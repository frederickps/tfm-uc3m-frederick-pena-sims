---
title: "Analysis"
format: html
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Analysis

### Library

```{r}
options(scipen = 999)
library(tidyverse)
library(readxl)
library(rDEA)
library(caret)
library(mice)
library(xgboost)
library(mapSpain)
library(kernelshap)
library(shapviz)
library(pdp)
```

### Load data (if needed)

```{r}
df_final <- read.csv("Data_2020/TFM_data_2024-06-03.csv", colClasses = c(INE = "character")) |> 
  select(-X)
```

### Data Envelopment Analysis

Ideas:

Unemployment as outcome Contracts as outcome (contracts per capita)

-   variables for DEA:

-   n_firms

-   per capita CCAA spending

-   per capita mun spending

-   distance

-   unemployment rate

-   variables for prediction task

    -   how money was spent
    -   population (absolute number)
    -   pop share foreigners
    -   pop share working age
    -   average age
    -   median income per household unit (?)
    -   contracts mean 2023
    -   greater 20k
    -   pop density

More idea - contracts divided by area (contracts database)

------------------------------------------------------------------------

In the context of Data Envelopment Analysis (DEA) and efficiency estimation, censoring refers to the phenomenon where efficiency scores are bounded or capped at a certain value. This means that despite variations in input-output combinations among decision-making units (DMUs), a substantial number of DMUs are assigned the maximum efficiency score (often 1) by the DEA model.

When efficiency scores are "censored," it implies that the DEA model is unable to distinguish between highly efficient DMUs, resulting in a clustering of efficiency scores at the upper bound (e.g., 1). This can occur due to various factors such as data limitations, measurement errors, model assumptions, or the inherent characteristics of the production process being analyzed.

------------------------------------------------------------------------

Taking the inverse of unemployment because output oriented DEA defines higher values as better

Using per capita spending on CCAA level and distance from provincial capital as environmental variables

Variable Returns to Scale (RTS = "Variable"): This assumption allows for flexibility in the relationship between inputs and outputs. It recognizes that the impact of municipal spending on reducing unemployment may vary across municipalities due to factors such as local economic conditions, labor market dynamics, and policy effectiveness.

## DEA

```{r}
X <- df_final[c("n_firms", "per_capita_MUN")]

Y <- df_final[c("target", "median_inc_con_unit")]
Y <- 
  Y |> 
  mutate(target = (target * -1)+100)

Z <- df_final[c("dist_prov_cap", "per_capita_CCAA")]



# Mean normalization function
mean_normalize <- function(x) {
  return((x - mean(x)) / (max(x) - min(x))+1)
}

# Apply mean normalization to each column
X <- X |>  mutate(across(everything(), mean_normalize))

Z <- Z |>  mutate(across(everything(), mean_normalize))

Y <- Y |> mutate(across(everything(), mean_normalize))

dea_robust <- 
  dea.env.robust(X, Y, W=NULL, Z, model="output", RTS="variable",
                L1=10, L2=100, alpha=0.05)
```

Calculating the efficiency score

```{r}
sorted_scores <- sort(dea_robust$delta_hat_hat, decreasing = TRUE)
best_score <- max(sorted_scores)
delta_hat_hat <- dea_robust$delta_hat_hat

df_dea <- 
  df_final |> 
  mutate(dea_robust = delta_hat_hat/best_score) 
```

## Descriptive Analysis

### Distribution DEA

```{r}
df_dea |> 
  ggplot()+
  geom_histogram(aes(log(dea_robust)), stat = "bin", bins = 160)
```

#### Most efficient municipalities

```{r}
df_dea |> 
  filter(dea_robust == 1) |> 
  count()
```

```{r}
df_dea |> 
  filter(dea_robust == 1)
```

#### Mean efficiency score

```{r}
mean(df_dea$dea_robust)
```

7808061

#### t-test between city sizes

```{r}
greater_20k <- df_dea[df_dea$greater_20k == 1, "dea_robust"]
smaller_20k <- df_dea[df_dea$greater_20k == 0, "dea_robust"]

# Perform the t-test
t_test_result <- t.test(greater_20k, smaller_20k)
t_test_result
```

Smaller municipalities are more efficient

```{r}
greater_100k <- df_dea[df_dea$pop_total > 100000, "dea_robust"]
smaller_100k <- df_dea[df_dea$pop_total <= 100000, "dea_robust"]

# Perform the t-test
t_test_result <- t.test(greater_100k, smaller_100k)
t_test_result
```

a bit more pronounced

## Feature Selection and Engineering

### Variable selection

All variables without additional meaning and variables used in estimating efficiency score+

No revenue data - resembles spending data

delted this revenue data:
, revenue_grants, revenue_other, revenue_tax_per_capita, revenue_grants_per_capita, revenue_other_per_capita,per_capita_revenue,

also deleted population (too little information)
, pop_smaller_5k, pop_5k_to_20k, pop_20k_to_50k, pop_50k_above

```{r}
df_model <- 
  df_dea |> 
  select(-c(CCAA, CODAUTO, CPRO, total_CCAA, total_MUN, target, dist_prov_cap, per_capita_CCAA, per_capita_MUN, n_firms, contracts_mean_2020, median_inc_con_unit,  per_capita_ccaa_general_services,per_capita_ccaa_security, per_capita_ccaa_economic, per_capita_ccaa_housing_services, per_capita_ccaa_culture, per_capita_ccaa_social_protection))
```

Data chosen I
, share_essential_business, share_essential_employment, per_capita_ccaa_general_services,per_capita_ccaa_security, per_capita_ccaa_economic, per_capita_ccaa_housing_services, per_capita_ccaa_culture, per_capita_ccaa_social_protection

Data chosen II
share_ccaa_general_services, share_ccaa_security, share_ccaa_economic, share_ccaa_housing_services, share_ccaa_culture, share_ccaa_social_protection

### Data report

```{r}
library(DataExplorer)
```

### Data imputation

```{r}
m <- 5
set.seed(475)
imp <- mice(df_model, m = m, method= "rf")
df_model_imp <- complete(imp, action=m)
```

### Correlation - robust

```{r}
df_model_robust <- df_model_imp |> 
  select(-c(INE, NOMBRE)) |> 
  filter(!is.na(party_mun)) |> 
  drop_na()
```



```{r}
df_corr <-
  df_model_robust |> 
  dplyr::select(-dea_robust) |>
  select_if(is.numeric)

corr<- cor(df_model_robust$dea_robust, df_corr, method = "spearman")
corr<-round(corr,4)

df_corr_results <- 
  data.frame(corr) |> 
  pivot_longer(values_to = "correlation",
               cols = 1:48,
               names_to = "variable")

ggplot(df_corr_results, aes(x = variable, y = correlation)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Correlation with DEA efficiency score", x = "Variable", y = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) 
```

### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train(dea_robust ~ .,
                     data = df_model_robust,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```

#### Data chosen I - CCAA per capita

[1] "party_munOTROS"                    "party_munPSOE"                     "party_munN.ADS."                  
 [4] "party_munUCIN"                     "party_munAxSI"                     "party_munBNG"                     
 [7] "party_munPAR"                      "party_munUPL"                      "party_ccaaERC"                    
[10] "party_ccaaPNV"                     "party_ccaaPSOE"                    "general_services"                 
[13] "environment"                       "social_services"                   "agr_farm_fish"                    
[16] "tax_fin_admin"                     "public_debt"                       "health"                           
[19] "education"                         "infrastructure"                    "employment_promotion"             
[22] "sports"                            "pub_transportation"                "area_sqkm"                        
[25] "ue_pct_2020"                       "pop_share_foreigners"              "pop_share_wk_age"                 
[28] "pop_share_retirees"                "share_essential_business"          "share_essential_employment"       
[31] "rural_prop_tax"                    "special_prop_tax"                  "min_coef_turn_tax"                
[34] "per_capita_ccaa_general_services"  "per_capita_ccaa_security"          "per_capita_ccaa_economic"         
[37] "per_capita_ccaa_culture"           "per_capita_ccaa_social_protection" "pop_density"                      
[40] "per_capita_contracts"              "revenue_tax_share"               

#### Data chosen II
[1] "party_munPP"                  "party_munOTROS"               "party_munPSOE"               
 [4] "party_munN.ADS."              "party_munUCIN"                "party_munAxSI"               
 [7] "party_munBNG"                 "party_munPAR"                 "party_munUPL"                
[10] "party_ccaaERC"                "party_ccaaPNV"                "party_ccaaPRC"               
[13] "party_ccaaPSOE"               "general_services"             "environment"                 
[16] "social_services"              "agr_farm_fish"                "tax_fin_admin"               
[19] "public_debt"                  "health"                       "education"                   
[22] "infrastructure"               "employment_promotion"         "sports"                      
[25] "pub_transportation"           "area_sqkm"                    "ue_pct_2020"                 
[28] "pop_share_foreigners"         "pop_share_wk_age"             "pop_share_retirees"          
[31] "share_essential_business"     "share_essential_employment"   "rural_prop_tax"              
[34] "special_prop_tax"             "min_coef_turn_tax"            "share_ccaa_general_services" 
[37] "share_ccaa_economic"          "share_ccaa_culture"           "share_ccaa_social_protection"
[40] "pop_density"                  "per_capita_contracts"         "revenue_tax_share" 

```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "party")&!startsWith(non_zero_vars, "greater")]


df_model_final <- 
  df_model_imp |>
  dplyr::select(all_of(non_zero_vars), dea_robust, party_mun, INE, NOMBRE,party_ccaa)|> 
  filter(!is.na(party_mun)) |> 
  drop_na()
# excluded party ccaa for the moment

# all_of(non_zero_vars), dea_robust, greater_20k, party_mun, party_ccaa, INE, NOMBRE
```

Hypothesis: covid employment data makes models overfit --\> too accurate AND decreases R-squared. How?

### Modelling

#### Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_model_final$dea_robust |> 
  createDataPartition(p = 0.75, list = FALSE)

train.data  <- df_model_final[training.samples, ]
test.data <- df_model_final[-training.samples, ] 

# deleting INE and NOMBRE from train set to keep in test only
train.data$INE <- NULL
train.data$NOMBRE <- NULL

```

#### Target normal - Random forest

```{r}
set.seed(3456)
rf_tune <- train(dea_robust ~., 
                 data = train.data,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(18,21)),
                 importance = TRUE)

rf_tune$finalModel$importance

rf_tune$results

varImp(rf_tune)

plot(varImp(rf_tune))
```

##### Results

See data chosen I
0.6485436 
MAE
0.03261175

Data chosen II
0.6504064
MAE
0.03264785

--\> constant problem: overfitting (test-resample mostly 57-58)

-   **MAE Interpretation:** MAE (Mean Absolute Error) represents the average difference between the predicted values and the actual values. In your case, the average difference is only 0.034, which is a very small portion of the target variable's range (0.5 to 1).

-   **Relative Error:** Considering the limited range of the target variable (from 0.5 to 1), an absolute error of 0.034 is even more significant. It translates to a maximum relative error of around 6.8% (0.034 / (1-0.5) ).

**General Rule of Thumb:**

-   A lower MAE indicates better model performance. In general, an MAE less than 10% of the variable's range is considered good. Here, your MAE is well below that threshold.

Prediction

#### Target log - Random forest

```{r}
set.seed(3456)
rf_tune_log <- train(log(dea_robust) ~., 
                 data = train.data,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(9,12,15,18,21)),
                 importance = TRUE)

rf_tune_log$finalModel$importance

rf_tune_log$results

varImp(rf_tune_log)

plot(varImp(rf_tune_log))
```

##### Results

see data chosen I
0.6540520

MAE
0.04215671

see data chosen II
0.6578412
MAE
0.04214916

#### Target log10 - Random forest

```{r}
set.seed(3456)
rf_tune_log10 <- train(log10(dea_robust) ~., 
                 data = train.data,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(9,12,15,18,21)),
                 importance = TRUE)

rf_tune_log10$finalModel$importance

rf_tune_log10$results

varImp(rf_tune_log10)

plot(varImp(rf_tune_log10))
```

##### Results

see data chosen I
0.6551247
MAE
0.01828085

see data chosen II
0.6588424
MAE
0.01826309

#### Target cube root - Random forest

```{r}
set.seed(3456)
rf_tune_cube <- train((dea_robust)^(1/3) ~., 
                 data = train.data,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(9,12,15,18,21)),
                 importance = TRUE)

rf_tune_cube$finalModel$importance

rf_tune_cube$results

varImp(rf_tune_cube)

plot(varImp(rf_tune_cube))
```

##### Results

see data chosen I
0.6541936
MAE
0.01287778

see data chosen II
0.6540056
MAE
0.01297889

#### Test data comparison

```{r}
test_results <- data.frame(dea_robust = test.data$dea_robust)
#normal
test_results$rf <- predict(rf_tune, test.data)
postResample(pred = test_results$rf,  obs = test_results$dea_robust)
# log
test_results$rf_log <- predict(rf_tune_log, test.data)
postResample(pred = test_results$rf_log,  obs = test_results$dea_robust)
# log10
test_results$rf_log10 <- predict(rf_tune_log10, test.data)
postResample(pred = test_results$rf_log10,  obs = test_results$dea_robust)
# cube
test_results$rf_cube <- predict(rf_tune_cube, test.data)
postResample(pred = test_results$rf_cube,  obs = test_results$dea_robust)
```
##### Excluding party data and employment in covid data 

see data chosen I
Normal
 RMSE   Rsquared        MAE 
0.04348254 0.63551313 0.03342641 
Log
     RMSE  Rsquared       MAE 
1.0349068 0.6321799 1.0339004 
Log10
     RMSE  Rsquared       MAE 
0.8864418 0.6377261 0.8849826 
Cube
     RMSE  Rsquared       MAE 
0.1564581 0.6334893 0.1461005 

-\-> strong overfitting

see data chosen II
Normal
      RMSE   Rsquared        MAE 
0.04340711 0.63832142 0.03360933 
Log
     RMSE  Rsquared       MAE 
1.0348870 0.6334083 1.0338983 
Log10
     RMSE  Rsquared       MAE 
0.8861580 0.6358376 0.8846834 
Cube
     RMSE  Rsquared       MAE 
0.1564919 0.6346190 0.1461201 

-\-> again strong overfitting 

#### Visualizing best

```{r}
qplot(test_results$rf, test_results$dea_robust) + 
  labs(title="RF Regression Observed VS Predicted", x="Predicted", y="Observed") +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  theme_bw()
```

#### Normalizing data - Normal target - RF

taking normal target variable best MAE rsquared combination


### MAE Investigation

```{r}
# normal
mae_per_observation_rf <- abs(test_results$rf - test_results$dea_robust)
test.data$mae_rf <- mae_per_observation_rf

# log
mae_per_observation_rf_log <- abs(test_results$rf_log - test_results$dea_robust)
test.data$mae_rf_log <- mae_per_observation_rf_log

# log10
mae_per_observation_rf_log10 <- abs(test_results$rf_log10 - test_results$dea_robust)
test.data$mae_rf_log10 <- mae_per_observation_rf_log10

# cube
mae_per_observation_rf_cube <- abs(test_results$rf_cube - test_results$dea_robust)
test.data$mae_rf_cube <- mae_per_observation_rf_cube
```

```{r}
df_mae <- 
  test.data |> 
  select(INE, NOMBRE, mae_rf, mae_rf_log, mae_rf_log10, mae_rf_cube) |> 
  left_join(df_dea, by = c("INE", "NOMBRE")) |> 
  drop_na()

# data chosen I - per capita
df_mae_I <- df_mae
```

#### PDP

```{r}
partial(rf_tune$finalModel, pred.var = "ue_pct_2020", plot = TRUE, rug = T, train = train.data)
autoplot(pdp_rf) +
  labs(title = "Partial Dependence Plot", x = "Feature Name", y = "Predicted Outcome") +
  theme_minimal()

?partial
```

#### SHAP

Importance Bee Plot

```{r}
X <- train.data[sample(nrow(train.data), 1000), -which(names(train.data) == "dea_robust")]
bg_X <- train.data[sample(nrow(train.data), 100), -which(names(train.data) == "dea_robust")]

s <- kernelshap(rf_tune, X = X, bg_X = bg_X) 
sv <- shapviz(s)
sv_importance(sv, kind = "bee", max_display = Inf)
```

Dependence

```{r}
v_select_1 <- c("per_capita_contracts", "pop_density", "pop_share_wk_age", "area_sqkm", "rural_prop_tax", "social_services", "employment_promotion", "party_mun")
sv_dependence(sv, v = v_select_1)
```

Backup

```{r}
library(iml)
# Create a predictor object
predictor <- Predictor$new(rf_tune, data = train.data, y = train.data$dea_robust)

# Compute SHAP values
shapley <- Shapley$new(predictor, x.interest = train.data[1, ])  # Example for first observation
shapley$plot()
```

#### Correlation Analysis

```{r}
df_corr_mae <-
  df_mae |> 
  select_if(is.numeric) |> 
  select(-MAE)

corr_mae<- cor(df_mae$MAE, df_corr_mae)
corr_mae<-round(corr_mae,4)

df_corr_mae_results <- 
  data.frame(corr_mae) |> 
  pivot_longer(values_to = "correlation",
               cols = 1:69,
               names_to = "variable")

ggplot(df_corr_mae_results, aes(x = variable, y = correlation)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Correlation with absolute error", x = "Variable", y = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) 
```

##### dea_robust variable

```{r}
df_mae |> 
  ggplot()+
  geom_point(aes(x = dea_robust, y = mae_rf)) +
  theme_minimal()
```

##### Mapping MAE

```{r}
esp_can <- esp_get_country() 
can_prov <- esp_get_can_provinces()
can_box <- esp_get_can_box() 
munic <- esp_get_munic() 

munic <-    
  munic |>  
  rename(INE = LAU_CODE)

df_mae_map <- munic |> 
  left_join(df_mae, by = "INE")  

ggplot(esp_can) +
  geom_sf() +
  geom_sf(data = can_prov) +
  geom_sf(data = can_box) + 
  geom_sf(data = df_mae_map, aes(fill = MAE), color = "black", size = .5)+
  scale_fill_viridis_c(na.value = NA) +
  theme_minimal()
```

No spatial relationship

```{r}
df_mae |> 
  ggplot()+
  geom_point(aes(x = area_sqkm, y = MAE)) +
  theme_minimal()+
    coord_cartesian(xlim = c(0, 300), ylim = c(0, 0.18))
```

```{r}
ggplot(df_mae) +
    geom_point(aes(x = pop_density, y = MAE)) +
    theme_minimal() +
    coord_cartesian(xlim = c(0, 90), ylim = c(0, 0.18))
```

```{r}
ggplot(df_mae) +
    geom_point(aes(x = pop_total, y = MAE)) +
    theme_minimal() +
    coord_cartesian(xlim = c(0, 500), ylim = c(0, 0.18))
```

```{r}
ggplot(df_mae) +
    geom_point(aes(x = culture, y = MAE)) +
    theme_minimal() +
    coord_cartesian(xlim = c(0, 40), ylim = c(0, 0.18))
```

```{r}
df_mae |> 
  arrange(desc(MAE))
```

## Building the Model

### Adding features

bivariat:

pop_density --\> threshold:

average_age --\> threshold: 12

area_sqkm --\> trheshold: 60-70

pop_total --\> threshold: 500

## END

```{r}

yhat = test_results$rf
hist(yhat, col="lightblue")

y = test_results$dea_robust
error = y-yhat
hist(error, col="lightblue")

noise <- error[1:100]

lwr <- yhat[101:length(yhat)] + quantile(noise,0.05, na.rm=T)
upr <- yhat[101:length(yhat)] + quantile(noise,0.95, na.rm=T)

predictions = data.frame(real=y[101:length(y)], fit=yhat[101:length(yhat)], lwr=lwr, upr=upr)

predictions = predictions %>% mutate(out=factor(if_else(real<lwr | real>upr,1,0)))

mean(predictions$out==1)

ggplot(predictions, aes(x=fit, y=real))+
  geom_point(aes(color=out)) + theme(legend.position="none") +
  geom_ribbon(data=predictions,aes(ymin=lwr,ymax=upr),alpha=0.3) +
  labs(title = "Prediction intervals", x = "Prediction",y="Estimated Efficiency")
```

#### XG Boost

```{r}
set.seed(123)
xgb_tune <- train(dea_robust ~., 
                  data = train.data,
                  method = "xgbTree",
                  preProc=c('scale','center'),
                  objective = "reg:squarederror",
                  trControl = ctrl,
                  tuneGrid = expand.grid(nrounds = c(700, 800, 900, 1000, 1500), 
                                         max_depth = c(7, 8), 
                                         eta = c(0.1),
                                         gamma = c(0.05, 0.1, 0.15),
                                         colsample_bytree = c(0.4, 0.5),
                                         min_child_weight = c(1),
                                         subsample = c(0.8)))

xgb_tune

plot(xgb_tune)
```
