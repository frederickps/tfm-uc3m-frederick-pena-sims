---
title: "Analysis"
format: html
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Analysis

### Install unusual packages

```{r}

```

### Library

Automatic

```{r}
check_and_install <- function(package) {
  if (!requireNamespace(package, quietly = TRUE)) {
    install.packages(package)
  }
  library(package, character.only = TRUE)
}

packages <- c(
  "devtools", "tidyverse", "corrplot", "readxl", "rDEA", 
  "caret", "mice", "xgboost", "mapSpain", "kernelshap", "shapviz", 
  "pdp", "factoextra", "patchwork", "sf", "scales", "psych", 
  "officer", "flextable"
)

sapply(packages, check_and_install)
```

To install catboost, follow the following step.
```{r, eval=FALSE}
install.packages('remotes')
remotes::install_url('https://github.com/catboost/catboost/releases/download/v1.2.5/catboost-R-windows-x86_64-1.2.5.tgz', INSTALL_opts = c("--no-multiarch", "--no-test-load"))
```

To load packages individually, follow the following step.
```{r}
options(scipen = 999)
library(catboost)
library(devtools)
library(tidyverse)
library(corrplot)
library(readxl)
library(rDEA)
library(caret)
library(mice)
library(xgboost)
library(mapSpain)
library(kernelshap)
library(shapviz)
library(pdp)
library(factoextra)
library(patchwork)
library(sf)
library(scales)
library(psych)
library(officer)
library(flextable)
```

### Load data (if needed)

```{r}
df_final <- read.csv("Data_2020/TFM_data_2024-06-12.csv", colClasses = c(INE = "character", greater_20k = "factor", CODAUTO = "character")) |> 
  select(-X)
```

Variable Returns to Scale (RTS = "Variable"): This assumption allows for flexibility in the relationship between inputs and outputs. It recognizes that the impact of municipal spending on reducing unemployment may vary across municipalities due to factors such as local economic conditions, labor market dynamics, and policy effectiveness.

## DEA

### Isotonocity 

The isotonicity property needs to be considered for each input-output pair individually. For Output 1, the data should not violate the isotonicity assumption. For Output 2, since the correlation is slightly negative but close to zero, the impact might be negligible, and the DEA model can still be constructed and interpreted meaningfully.

```{r}
df_iso <- 
  df_final |> 
  select(c(median_inc_con_unit, diff_ue, per_capita_MUN)) |> 
  mutate(diff_ue = (diff_ue * -1)+100)

corr_iso<- cor(df_iso, method = "pearson")
corrplot(corr_iso)
```

### Efficiency score estimation

Braking off into separate data sets and standardizing as is good practice

Difference between two years negated so negative values (reducing unemployment) are observed as better by DEA while greater differences are made negative. Constant added to not infringe on non-negative output.

```{r}
X <- df_final[c("per_capita_MUN")]

Y <- df_final[c("diff_ue", "median_inc_con_unit")]
Y <- 
  Y |> 
  mutate(diff_ue = ((diff_ue * -1)+100))

Z <- df_final[c("dist_prov_cap", "per_capita_CCAA", "per_capita_n_firms")]

# Mean normalization function
mean_normalize <- function(x) {
  return((x - mean(x)) / (max(x) - min(x))+1)
}

# Apply mean normalization to each column
X <- X |>  mutate(across(everything(), mean_normalize))

Z <- Z |>  mutate(across(everything(), mean_normalize))

Y <- Y |> mutate(across(everything(), mean_normalize))
```

#### Validating inverse assumption

```{r}
dea_naive <-
  dea(XREF = X, YREF = Y, X = X, Y = Y, W =NULL, RTS ="variable", model = "output")

df_dea_naive <-
  df_final |> 
  mutate(dea_naive = dea_naive$thetaOpt)
```


```{r}
df_dea_naive |> 
  arrange(desc(dea_naive)) |> 
  select(NOMBRE, CCAA, party_ccaa, party_mun, per_capita_MUN, dist_prov_cap, per_capita_n_firms, diff_ue, median_inc_con_unit, per_capita_CCAA, dea_naive) |> 
  head()
```

#### Environmental DEA estimation

Introducing data frames into Simar and Wilson (2007) model.

```{r}
dea_robust <- 
  dea.env.robust(X, Y, W=NULL, Z, model="output", RTS="variable",
                L1=10, L2=100, alpha=0.05)
```

Calculating the relative efficiency score, as efficiency scores are only provided in absolute terms.

```{r}
sorted_scores <- sort(dea_robust$delta_hat_hat, decreasing = TRUE)
best_score <- max(sorted_scores)
delta_hat_hat <- dea_robust$delta_hat_hat

df_dea <- 
  df_final |> 
  mutate(dea_robust = delta_hat_hat/best_score)
```

## Descriptive Analysis

### Efficiency score

#### In Appendix - Distribution

Included in Appendix of final paper 

Distribution of DEA Efficiency Score

```{r}
mean_val <- mean(df_dea$dea_robust)
median_val <- median(df_dea$dea_robust)
min_val <- min(df_dea$dea_robust)

Figure_B2 <- 
  df_dea |> 
  ggplot()+
  geom_histogram(aes(dea_robust), stat = "bin", bins = 100, fill = "steelblue") +
  theme_minimal() +
  scale_x_continuous(labels = percent_format(), breaks = seq(0.6, 1, by = 0.05)) + 
  labs(y = "Count",
       x = "Efficiency Score") +
  # Add annotations
  annotate("text", x = mean_val+0.05, y = Inf, label = paste("Mean:", percent(mean_val, accuracy = 0.1)), vjust = 2, color = "black", size = 3) +
  geom_segment(aes(x = mean_val, xend = mean_val+0.05, y = 120, yend = mean_val+125), color = "black") +
  annotate("text", x = median_val-0.07, y = Inf, label = paste("Median:", percent(median_val, accuracy = 0.1)), vjust = 2, color = "black", size = 3) +
  geom_segment(aes(x = median_val, xend = median_val-0.07, y = 120, yend = median_val+125), color = "black") +
  annotate("text", x = min_val+0.01, y = 50, label = paste("Min:", percent(min_val, accuracy = 0.1)), color = "black", size = 3)+
  geom_segment(aes(x = min_val, xend = min_val+0.01, y = min_val, yend = 47), color = "black")

Figure_B2
```
```{r}
ggsave(plot = Figure_B2, "Data_2020/Figures/Figure_B2.png", dpi = 300, bg = "white", width = 10, height = 7)
```


#### Most and least efficient municipalities

Finding most efficient municipalities

```{r}
df_dea |> 
  arrange(desc(dea_robust)) |> 
  select(INE, NOMBRE, CCAA, party_ccaa, party_mun, per_capita_MUN, dist_prov_cap, per_capita_n_firms, diff_ue, median_inc_con_unit, per_capita_CCAA, dea_robust) |> 
  head()
```

Least efficient

```{r}
df_dea |> 
  arrange(desc(dea_robust)) |> 
  select(NOMBRE, CCAA, party_ccaa, party_mun, per_capita_MUN, dist_prov_cap, per_capita_n_firms, diff_ue, median_inc_con_unit, per_capita_CCAA, dea_robust) |> 
  tail()
```


#### Environmental variables

robust coefficients in the truncated regression of reciprocal of DEA score on environmental variables (after the second loop).

```{r}
dea_robust$beta_hat_hat
```
#### Mean efficiency score

```{r}
mean(df_dea$dea_robust)
```

0.7701055

#### t-test between city sizes

```{r}
greater_20k <- df_dea[df_dea$greater_20k == 1, "dea_robust"]
smaller_20k <- df_dea[df_dea$greater_20k == 0, "dea_robust"]

# Perform the t-test
t_test_result <- t.test(greater_20k, smaller_20k)
t_test_result
```

Smaller municipalities are more efficient, statistically significant.

```{r}
greater_100k <- df_dea[df_dea$pop_total > 100000, "dea_robust"]
smaller_100k <- df_dea[df_dea$pop_total <= 100000, "dea_robust"]

# Perform the t-test
t_test_result <- t.test(greater_100k, smaller_100k)
t_test_result
```

A bit more pronounced if threshold difference between large and small municipality is greater.

#### In Text - Map

```{r}
esp_can <- esp_get_country() 
can_prov <- esp_get_can_provinces()
can_box <- esp_get_can_box() 
munic <- esp_get_munic() 

munic <-    
  munic |>  
  rename(INE = LAU_CODE)

df_dea_map <- munic |> 
  left_join(df_dea, by = "INE")  


Figure_2 <- 
  ggplot(esp_can) +
  geom_sf() +
  geom_sf(data = can_prov) +
  geom_sf(data = can_box) + 
  geom_sf(data = df_dea_map, aes(fill = dea_robust), color = "black", size = .5)+
  scale_fill_gradient(na.value = "grey", low ="#FF0000",high = "#FFFFFF",name = "Efficiency\nScore") +
  theme_void()

Figure_2
```

```{r}
ggsave(plot = Figure_2,"Data_2020/Figures/Figure_2.png", dpi = 300, width = 10, height = 7, bg = "white")
```


Seems to follow the notion that more money does not necessarily produce more efficent labour market outcomes (but often adverse relationship)

North more inefficient than South

### PCA

```{r}
df_pca <-
  df_dea |> 
  select_if(is.numeric) |> 
  select(-c(CODAUTO, CPRO, median_inc_con_unit, diff_ue, per_capita_CCAA, dist_prov_cap, n_firms, per_capita_n_firms, per_capita_MUN)) |> 
  drop_na()

set.seed(53456)
pca <- prcomp(df_pca, scale. = T)
```

#### In Appendix - PC variance

```{r}
screeplot <- fviz_screeplot(pca, addlabels = TRUE)

Figure_B3 <- 
  screeplot + ggtitle(NULL) +
  theme_minimal()

Figure_B3
```

```{r}
ggsave(plot = Figure_B3, "Data_2020/Figures/Figure_B3.png", dpi = 300, width = 10, height = 7, bg = "white")
```
 

Filtering less strong rotation values to get better overview

```{r}
# Create a data frame with PCA rotation values
data.frame(variable = rownames(pca$rotation), rotation_value = pca$rotation[, 1]) |>
  filter(rotation_value > 0.15 | rotation_value < -0.15) |> 
  ggplot(aes(x = variable, y = rotation_value)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Barplot of PCA (First Principal Component)",
       x = "Variable", y = "Rotation Value")  +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
#### In Text - PC 2

Filtering less strong rotation values to get better overview

Barplot of PCA (Second Prinicipal Component)
```{r}
Figure_3 <- 
  data.frame(variable = rownames(pca$rotation), rotation_value = pca$rotation[, 2]) |>
  filter(rotation_value > 0.1 | rotation_value < -0.1) |> 
  ggplot(aes(x = variable, y = rotation_value)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(y = "Rotation Value", x= "")  +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_x_discrete(labels = c("community_wellbeing" = "Com. Wellbeing", 
                              "dea_robust" = "Efficiency Score",
                              "employment_promotion" = "Employment Promotion", 
                              "gov_bodies" = "Government Bodies",
                              "party_mun_id" = "Party Ideology (MUN)", 
                              "dea_robust" = "Efficiency Score",
                              "per_capita_contracts" = "Contracts Per Capita", 
                              "revenue_grants_share" = "Share of Revenue Grants",
                              "revenue_other_share" = "Revenue Other Sources",
                              "revenue_tax_share" = "Share of Revenue Tax", 
                              "rural_prop_tax" = "Rural Property Tax Rate",
                              "share_ccaa_culture" = "Culture (CCAA)", 
                              "share_ccaa_housing_services" = "Housing Services (CCAA)",
                              "share_ccaa_security" = "Security (CCAA)", 
                              "share_ccaa_social_protection" = "Social Protection (CCAA)",
                              "share_contracts_agri" = "Share Contracts Agriculture Sector", 
                              "share_contracts_con" = "Share Contracts Construction Sector",
                              "share_contracts_indu" = "Share Contracts Industrial Sector", 
                              "share_contracts_serv" = "Share Contracts Service Sector",
                              "share_essential_employment" = "Share of Employment Essential", 
                              "share_ue_agriculture" = "Share Unemployment from Agriculture Sector",
                              "share_ue_construction" = "Share Unemployment from Construction Sector", 
                              "share_ue_service" = "Share Unemployment from Service Sector",
                              "social_services" = "Social Services", 
                              "ue_pct_2020" = "Unemployment Rate (2020)"))

Figure_3
```
```{r}
ggsave(plot = Figure_3,"Data_2020/Figures/Figure_3.png", bg ="white", width = 10, height = 7)
```



REST NOT INCLUDED

```{r}
data.frame(z1=pca$x[,1],z2=pca$x[,2]) %>% 
  ggplot(aes(z1,z2)) + geom_point(size=0) +
  labs(title="First two principal components (scores)", x="PC1", y="PC2") + #guides(color=guide_legend(title="HDI"))+
  theme_bw() +theme(legend.position="bottom")
```

```{r}
fviz_contrib(pca, choice = "var", axes = 1)
```

DEA does not contribute as much.

```{r}
fviz_contrib(pca, choice = "var", axes = 2)
```

DEA contributes the second most to component number two

### Clustering

```{r}
df_clus <-
  df_dea |> 
  select_if(is.numeric) |> 
  select(-c(CODAUTO, CPRO, diff_ue, median_inc_con_unit, per_capita_CCAA, per_capita_MUN)) |> 
  drop_na()
```

#### In Appendix - Optimal Cluster estimation
```{r}
fviz_nbclust <- fviz_nbclust(scale(df_clus), kmeans, method = 'silhouette', k.max = 40, nstart = 100)

Figure_B4 <- fviz_nbclust + ggtitle(NULL) +
  theme_minimal()

Figure_B4
```

```{r}
ggsave(plot = Figure_B4, "Data_2020/Figures/Figure_B4.png", dpi = 300, width = 10, height = 7, bg = "white")
```


```{r}
cluster <- kmeans(df_clus, centers = 2, nstart = 100)
```


#### In Text - Centers

```{r}
# Assuming 'cluster' is your k-means result
centers <- as.data.frame(cluster$centers)
centers$cluster <- factor(1:nrow(centers))  # Add a column for cluster labels

custom_labels <- c(
  general_services = "Share of Spending\nGeneral Services",
  pub_safety_mobility = "Share of Spending\nPublic Safety & Mobility",
  social_services = "Share of Spending\nSocial Services",
  infrastructure = "Share of Spending\nInfrastructure",
  employment_promotion = "Share of Spending\nEmployment Promotion",
  dist_prov_cap = "Distance to\nProvincial Capital",
  ue_pct_2020 = "Unemployment\nRate 2020",
  pop_share_retirees = "Share of Retirees",
  share_contracts_serv = "Share of Contracts\nin Service Sector",
  revenue_tax_share = "Municipal\nShare of Revenue:\nTax",
  pop_density = "Population Density",
  dea_robust = "Efficiency Score",
  pop_share_foreigners = "Share of Foreigners",
  share_essential_employment = "Share of\nEssential Employment",
  share_firms_service = "Share of Firms\nin Service Sector",
  housing_urban_plan = "Share of Spending\nHousing and Urban\nPlanning"
)


Figure_4 <- 
  centers |> 
  select(general_services, pub_safety_mobility, social_services, infrastructure, employment_promotion, dist_prov_cap, ue_pct_2020, pop_share_retirees, share_contracts_serv, revenue_tax_share, pop_density, dea_robust, cluster, pop_share_foreigners, share_essential_employment, share_firms_service, housing_urban_plan) |>
  pivot_longer(-cluster, names_to = "variable", values_to = "value") |>
  ggplot(aes(x = variable, y = value, fill = cluster)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  facet_wrap(~ variable, scales = "free", labeller = labeller(variable = custom_labels)) +
  labs(y = "Average Value", fill = "Cluster", x = "") + 
  theme_minimal() +
  theme(axis.text.x = element_blank(),
        legend.position =  "bottom")+
  scale_fill_manual(values = c("steelblue", "#FF0000"))

Figure_4
```

```{r}
ggsave(plot = Figure_4,"Data_2020/Figures/Figure_4.png", bg = "white", dpi = 300, width = 10, height = 7)
```


### In Text -Correlation

Spearman because most of the data is not normally distributed and relationships are not linear

Filtered 

Correlation with DEA efficiency score

```{r}
df_corr <-
  df_dea |> 
  select(-c(INE, NOMBRE, CPRO, CODAUTO, dea_robust, diff_ue, median_inc_con_unit, per_capita_MUN, per_capita_n_firms, per_capita_CCAA, dist_prov_cap)) |>
  select_if(is.numeric)

corr<- cor(df_dea$dea_robust, df_corr, method = "spearman", use = "complete.obs")
corr<-round(corr,4)

df_corr_results <- 
  data.frame(corr) |> 
  pivot_longer(values_to = "correlation",
               cols = 1:65,
               names_to = "variable")

Figure_5 <- 
  df_corr_results |> 
  filter(correlation > 0.1 | correlation < -0.1) |> 
  ggplot(aes(x = variable, y = correlation)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(y = "Correlation Coefficient", x = "") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+ 
  scale_x_discrete(labels = c("agr_farm_fish" = "Agriculture",
                              "area_sqkm" = "Area in Square KM",
                              "community_wellbeing" = "Com. Wellbeing", 
                              "employment_promotion" = "Employment Promotion",
                              "environment" = "Environment",
                              "gov_bodies" = "Government Bodies",
                              "ideology_score" = "Government Ideology Score",
                              "per_capita_contracts" = "Contracts Per Capita",
                              "public_debt" = "Serving Public Debt",
                              "pub_transportation" = "Public Transportation",
                              "revenue_grants_share" = "Share of Revenue Grants",
                              "revenue_tax_share" = "Share of Revenue Tax", 
                              "rural_prop_tax" = "Rural Property Tax Rate",
                              "share_ccaa_culture" = "Culture (CCAA)", 
                              "share_ccaa_economic" = "Economic (CCAA)",
                              "share_ccaa_general_services" = "General Services (CCAA)",
                              "share_ccaa_housing_services" = "Housing Services (CCAA)",
                              "share_ccaa_security" = "Security (CCAA)", 
                              "share_ccaa_social_protection" = "Social Protection (CCAA)",
                              "share_contracts_agri" = "Share Contracts Agriculture Sector", 
                              "share_contracts_con" = "Share Contracts Construction Sector",
                              "share_contracts_indu" = "Share Contracts Industrial Sector", 
                              "share_contracts_serv" = "Share Contracts Service Sector",
                              "share_firms_service" = "Share Firms Service Sector", 
                              "share_ue_agriculture" = "Share Unemployment from Agriculture Sector",
                              "share_ue_construction" = "Share Unemployment from Construction Sector",
                              "share_ue_service" = "Share Unemployment from Service Sector",
                              "share_ue_industry" = "Share Unemployment from Industry Sector",
                              "social_services" = "Social Services", 
                              "ue_pct_2020" = "Unemployment Rate (2020)"))

Figure_5
```
```{r}
ggsave(plot = Figure_5,"Data_2020/Figures/Figure_5.png", dpi = 300, width = 10, height = 7, bg = "white")
```

## Data imputation

Deleting unnsecessary variables

All variables without additional meaning and variables used in estimating efficiency score+

No revenue data - resembles spending data

```{r}
df_model <- 
  df_dea |> 
  select(-c(CODAUTO, dist_prov_cap, per_capita_CCAA, per_capita_MUN, per_capita_n_firms, median_inc_con_unit, party_mun, party_ccaa, diff_ue))
```

```{r}
m <- 5
set.seed(475)
imp <- mice(df_model, m = m, method= "rf")
df_model_imp <- complete(imp, action=m)
```

## Target variable evaluation

```{r}
df_model_robust <- df_model_imp |> 
  select(-c(INE, NOMBRE, CCAA, CPRO)) 
```

## Modelling - Target normal - Random forest

### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train(dea_robust ~ .,
                     data = df_model_robust,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```

```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "party")&!startsWith(non_zero_vars, "greater")]


df_model_final <- 
  df_model_imp |>
  dplyr::select(all_of(non_zero_vars), dea_robust, greater_20k, INE, NOMBRE) |> 
  drop_na()
# excluded , party_mun,party_ccaa for the moment

# all_of(non_zero_vars), dea_robust, greater_20k, party_mun, party_ccaa, INE, NOMBRE
```

#### Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_model_final$dea_robust |> 
  createDataPartition(p = 0.75, list = FALSE)

train.data_pre_no  <- df_model_final[training.samples, ]
test.data_pre_no <- df_model_final[-training.samples, ] 

# deleting INE and NOMBRE from train set to keep in test only
train.data_pre_no$INE <- NULL
train.data_pre_no$NOMBRE <- NULL

```

#### Training RF
```{r}
ctrl <- trainControl(method = "cv", number = 5)

set.seed(3456)
rf_tune <- train(dea_robust ~., 
                 data = train.data_pre_no,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(16)),
                 importance = TRUE)
```

##### Results

```{r}
test_results <- data.frame(dea_robust = test.data_pre_no$dea_robust)

#normal
test_results$rf <- predict(rf_tune, test.data_pre_no)
postResample(pred = test_results$rf,  obs = test_results$dea_robust)
```
## Modelling - Target log - Random forest

### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train(log(dea_robust) ~ .,
                     data = df_model_robust,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```
  
```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "party")&!startsWith(non_zero_vars, "greater")]


df_model_final <- 
  df_model_imp |>
  dplyr::select(all_of(non_zero_vars), dea_robust, INE, NOMBRE)|>
  drop_na()
# excluded , party_mun,party_ccaa for the moment
```

#### Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_model_final$dea_robust |> 
  createDataPartition(p = 0.75, list = FALSE)

train.data_pre_log  <- df_model_final[training.samples, ]
test.data_pre_log <- df_model_final[-training.samples, ] 

# deleting INE and NOMBRE from train set to keep in test only
train.data_pre_log$INE <- NULL
train.data_pre_log$NOMBRE <- NULL

```

#### Training RF
```{r}
ctrl <- trainControl(method = "cv", number = 5)

set.seed(3456)
rf_tune_log <- train(log(dea_robust) ~., 
                 data = train.data_pre_log,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(18)),
                 importance = TRUE)
```

##### Results

```{r}
# log
test_results$rf_log <- predict(rf_tune_log, test.data_pre_log)
test_results$rf_log <- exp(test_results$rf_log)
rf_log <- postResample(pred = test_results$rf_log,  obs = test_results$dea_robust)
```

## Modelling - Target log10 - Random forest
### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train(log10(dea_robust) ~ .,
                     data = df_model_robust,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```


```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "party")&!startsWith(non_zero_vars, "greater")]


df_model_final <- 
  df_model_imp |>
  dplyr::select(all_of(non_zero_vars), dea_robust, INE, NOMBRE)|> 
  drop_na()
# excluded party ccaa for the moment
```

#### Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_model_final$dea_robust |> 
  createDataPartition(p = 0.75, list = FALSE)

train.data_pre_log10  <- df_model_final[training.samples, ]
test.data_pre_log10 <- df_model_final[-training.samples, ] 

# deleting INE and NOMBRE from train set to keep in test only
train.data_pre_log10$INE <- NULL
train.data_pre_log10$NOMBRE <- NULL

```

#### Training RF
```{r}
ctrl <- trainControl(method = "cv", number = 5)

set.seed(3456)
rf_tune_log10 <- train(log10(dea_robust) ~., 
                 data = train.data_pre_log10,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(18)),
                 importance = TRUE)
```

##### Results

```{r}
# log10
test_results$rf_log10 <- predict(rf_tune_log10, test.data_pre_log10)
test_results$rf_log10 <- 10^(test_results$rf_log10)
rf_log10 <- postResample(pred = test_results$rf_log10,  obs = test_results$dea_robust)
```

## Target cube root - Random forest

### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train((dea_robust)^(1/3) ~ .,
                     data = df_model_robust,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```
 
```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "party")&!startsWith(non_zero_vars, "greater")]


df_model_final <- 
  df_model_imp |>
  dplyr::select(all_of(non_zero_vars), dea_robust, INE, NOMBRE)|> 
  drop_na()
# excluded party ccaa for the moment
```

#### Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_model_final$dea_robust |> 
  createDataPartition(p = 0.75, list = FALSE)

train.data_pre_cub  <- df_model_final[training.samples, ]
test.data_pre_cub <- df_model_final[-training.samples, ] 

# deleting INE and NOMBRE from train set to keep in test only
train.data_pre_cub$INE <- NULL
train.data_pre_cub$NOMBRE <- NULL
```

#### Training RF
```{r}
ctrl <- trainControl(method = "cv", number = 5)

set.seed(3456)
rf_tune_cube <- train((dea_robust)^(1/3) ~., 
                 data = train.data_pre_cub,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(15)),
                 importance = TRUE)
```

##### Results
```{r}
# cube
test_results$rf_cube <- predict(rf_tune_cube, test.data_pre_cub)
test_results$rf_cube <- (test_results$rf_cube)^3
rf_cube <- postResample(pred = test_results$rf_cube,  obs = test_results$dea_robust)
```

#### In Text - Compare Results

```{r}
cube_df <- as.data.frame(t(rf_cube))
log_df <- as.data.frame(t(rf_log))
normal_df <- as.data.frame(t(rf_normal))
log10_df <- as.data.frame(t(rf_log10))

cube_df$model <- "Cube Root"
log_df$model <- "Log"
normal_df$model <- "Normal"
log10_df$model <- "Log10"

rf_metrics_table <- rbind(normal_df, log_df,  log10_df, cube_df)

rf_metrics_table
```


## MAE Investigation

```{r}
# normal
mae_per_observation_rf <- abs(test_results$rf - test_results$dea_robust)
test.data_pre_no$mae_rf <- mae_per_observation_rf 
```

```{r}
df_mae <- 
  test.data_pre_no |> 
  select(INE, NOMBRE, mae_rf) |> 
  left_join(df_dea, by = c("INE", "NOMBRE")) |> 
  drop_na()
```

### In Text - Efficiency and Absolute Error

```{r}
Figure_6 <- 
  df_mae |> 
  ggplot()+
  geom_point(aes(x = dea_robust, y = mae_rf)) +
  theme_minimal() +
  labs(y = "Absolute Error", x = "Predicted Efficiency Score")

Figure_6
```

```{r}
ggsave(plot = Figure_6,"Data_2020/Figures/Figure_6.png", bg = "white", width = 10, height = 7, dpi = 300)
```


### In Appendix - Correlation Analysis

```{r}
df_corr_mae <-
  df_mae |> 
  select_if(is.numeric) |> 
  select(-mae_rf)

corr_mae<- cor(df_mae$mae_rf, df_corr_mae, method = "spearman")
corr_mae<-round(corr_mae,4)

df_corr_mae_results <- 
  data.frame(corr_mae) |> 
  pivot_longer(values_to = "correlation",
               cols = 1:69,
               names_to = "variable")


Figure_B6 <- 
  df_corr_mae_results |> 
  filter(correlation > 0.1 | correlation < -0.1) |> 
  ggplot(aes(x = variable, y = correlation)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(x = "",
       y = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  scale_x_discrete(labels = c("area_sqkm" = "Area in Square KM",
                              "average_age" = "Average Age", 
                              "business_turism_sme" = "Business, Tourism, and SMEs",
                              "education" = "Education",
                              "gov_bodies" = "Government Bodies",
                              "n_firms" = "Absolute Number of Firms",
                              "other_econ" = "Other Economic Spending",
                              "party_mun_id" = "Municipality Governing Party Ideology",
                              "pop_density" = "Population Density",
                              "pop_share_youth" = "Share of Youth",
                              "pop_total" = "Total Population",
                              "pub_safety_mobility" = "Public Safety and Mobility", 
                              "public_debt" = "Spending on Public Debt",
                              "share_ccaa_housing_services" = "Housing Services (CCAA)",
                              "share_ccaa_security" = "Security (CCAA)",  
                              "share_contracts_con" = "Share Contracts Construction Sector",
                              "share_essential_business" = "Share of Essential Businesses",
                              "share_firms_service" = "Share Firms Service Sector",
                              "share_women" = "Share Women", 
                              "social_services" = "Social Services",
                              "sports" = "Sports", 
                              "tax_fin_admin" = "Financial Administration"))

Figure_B6
```
```{r}
ggsave(plot = Figure_B6, "Data_2020/Figures/Figure_B6.png", bg = "white", dpi = 300, width = 10, height = 7)
```

### In Appendix - Mapping MAE

```{r}
esp_can <- esp_get_country() 
can_prov <- esp_get_can_provinces()
can_box <- esp_get_can_box() 
munic <- esp_get_munic() 

munic <-    
  munic |>  
  rename(INE = LAU_CODE)

df_mae_map <- munic |> 
  left_join(df_mae, by = "INE")  

Figure_B5 <- ggplot(esp_can) +
  geom_sf() +
  geom_sf(data = can_prov) +
  geom_sf(data = can_box) + 
  geom_sf(data = df_mae_map, aes(fill = mae_rf), color = "black", size = .5)+
  scale_fill_gradient(na.value = "grey", high ="#FF0000",low = "steelblue",name = "Absolute\nError")+
  theme_void()

Figure_B5
```

```{r}
ggsave(plot = Figure_B5, "Data_2020/Figures/Figure_B5.png", dpi = 300, bg = "white", width = 10, height = 7)
```


### Not included - Linear regression

```{r}
df_mae_lm <-
  na.omit(df_mae) |> 
  select(-c(INE, NOMBRE, CCAA, party_ccaa, party_mun, median_inc_con_unit, target, dea_robust))
model <- lm(mae_rf ~ ., data = df_mae_lm)

# Print summary of the model
summary(model)
```
### Absoulte error by Regions (Province and Autonomous Community)

#### In Text - Province

```{r}
CPRO_mae <- df_mae |> 
  group_by(CPRO) |> 
  summarise(mae_rf = mean(mae_rf, na.rm = TRUE))

# Create the graph
Figure_7 <- 
  ggplot(CPRO_mae, aes(x = CPRO, y = mae_rf)) +
  geom_bar(stat = "identity", fill = "steelblue", color = "black") +
  labs(x = "Regional Area Code",
       y = "Mean Absolute Error") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

Figure_7
```
```{r}
ggsave(plot = Figure_7,"Data_2020/Figures/Figure_7.png", bg = "white", width = 10, height = 7, dpi = 300)
```

Not included

Mean Absolute Error by Province

Map

```{r}
esp_can <- esp_get_country() 
can_prov <- esp_get_can_provinces()
can_box <- esp_get_can_box() 
provs <- esp_get_prov_siane(epsg = 3857)

df_mae_prov <- provs |> 
  left_join(CPRO_mae, by = c("cpro" = "CPRO"))  

ggplot(esp_can) +
  geom_sf() +
  geom_sf(data = can_prov) +
  geom_sf(data = can_box) + 
  geom_sf(data = df_mae_prov, aes(fill = mae_rf), color = "black", size = .5)+
  scale_fill_viridis_c(na.value = NA) +
  theme_minimal()
```

#### Not Included - Autnomous communities

```{r}
CCAA_mae <- df_mae |> 
  group_by(CCAA, CODAUTO) |> 
  summarise(mae_rf = mean(mae_rf, na.rm = TRUE))

# Create the graph
ggplot(CCAA_mae, aes(x = CCAA, y = mae_rf)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Mean Absolute Error by CCAA",
       x = "Autonomous Community",
       y = "Mean Absolute Error") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Mapping
```{r}
esp_can <- esp_get_country() 
can_prov <- esp_get_can_provinces()
can_box <- esp_get_can_box() 
CCAA_sf <- esp_get_ccaa()

df_mae_ccaa <- CCAA_sf |> 
  left_join(CCAA_mae, by = c("codauto" = "CODAUTO"))  

ggplot(esp_can) +
  geom_sf() +
  geom_sf(data = can_prov) +
  geom_sf(data = can_box) + 
  geom_sf(data = df_mae_ccaa, aes(fill = mae_rf), color = "black", size = .5)+
  scale_fill_viridis_c(na.value = NA) +
  theme_minimal()
```

### In Appendix - Scatter plots
```{r}
pb1 <- 
  ggplot(df_mae) +
    geom_point(aes(x = pop_total, y = mae_rf)) +
    theme_minimal() +
    coord_cartesian(xlim = c(100, 2000), ylim = c(0, 0.18)) +
  labs(x = "Total Population",
       y = "Absolute Error")

```

```{r}
pb2 <- 
  ggplot(df_mae) +
    geom_point(aes(x = pop_density, y = mae_rf)) +
    theme_minimal() +
    coord_cartesian(xlim = c(0, 60), ylim = c(0, 0.18))+
  labs(x = "Population Density",
       y = "Absolute Error")
```

```{r}
pb3 <- 
  ggplot(df_mae) +
    geom_point(aes(x = area_sqkm, y = mae_rf)) +
    theme_minimal() +
    coord_cartesian(xlim = c(0, 300), ylim = c(0, 0.18))+
  labs(x = "Area in sqkm",
       y = "Absolute Error")
```

```{r}
Figure_B7 <- wrap_plots(pb1, pb2, pb3, ncol = 1)

Figure_B7
```

```{r}
ggsave(plot = Figure_B7, "Data_2020/Figures/Figure_B7.png", dpi = 300, bg = "white", height = 12, width = 10)
```


## Building the Model

### Feature Engineering

Selecting imputed data frame while keeping CCAA and CPRO

```{r}
df_ml <- 
  df_model_imp |> 
  select(-c(INE, NOMBRE, CCAA)) |> 
  mutate(CPRO = as.factor(CPRO))
```

Adding features

bivariat:

pop_density --\> threshold: 50

area_sqkm --\> trheshold: 50

pop_total --\> threshold: 500

keep CPRO

Interactions:

All of the above with all variables except pca and dea

Function
```{r}
generate_interactions <- function(df) {
  # Extracting numeric columns excluding dea_robust
  numeric_cols <- df %>%
    select(where(is.numeric), -dea_robust)
  
  # Extracting pop_total column
  pop_total_col <- numeric_cols %>%
    select(pop_total, pop_density, area_sqkm)
  
  # Other numeric columns excluding pop_total
  other_numeric_cols <- numeric_cols %>%
    select(-c(pop_total, pop_density, area_sqkm))
  
  # Generating interactions
  interaction_cols <- list()
  
  for(col_name in names(other_numeric_cols)) {
    interaction_name <- paste("pop_total", col_name, sep = "_x_")
    interaction_name <- make.names(interaction_name, unique = TRUE)  # Ensure unique column names
    interaction_cols[[interaction_name]] <- pop_total_col[[1]] * other_numeric_cols[[col_name]]
  }
  
  # Combining original and interaction columns
  df_interactions <- cbind(df, as.data.frame(interaction_cols))
  
  return(df_interactions)
}
```

```{r}
# to apply feature engineering
vars_to_engineer <- 
  df_ml |> 
  select(where(is.numeric)) |> 
  names()

# feature engineering
df_ml <- 
  df_ml |> 
  mutate(pop_density_low = as.factor(if_else(pop_density < 50, 1,0)), # adding varaibles
         pop_total_low = as.factor(if_else(pop_total < 500, 1,0)),
         area_sqkm_low = as.factor(if_else(area_sqkm < 50, 1,0))) |>
  generate_interactions() |> 
  mutate(across(all_of(vars_to_engineer), ~log(. + 1), .names = "{.col}_log"), # feature engineering mathematical alteration of variables
         across(all_of(vars_to_engineer), ~.^2, .names = "{.col}_2"),
         across(all_of(vars_to_engineer), ~.^3, .names = "{.col}_3")) |> 
  mutate(pop_total_x_area_sqkm = area_sqkm*pop_total,
         pop_density_X_area_sqkm = pop_density * area_sqkm,
         pop_total_x_pop_density = pop_total*pop_density) |> 
  drop_na()

df_ml$dea_robust_2 <- NULL
df_ml$dea_robust_log <- NULL
df_ml$dea_robust_3 <- NULL
```

## Feature selection

### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train(dea_robust ~ .,
                     data = df_ml,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```

```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "CPRO")&!startsWith(non_zero_vars, "greater")&!endsWith(non_zero_vars, "low1")]

df_ml_final <- 
  df_ml |> 
  dplyr::select(all_of(non_zero_vars), dea_robust, CPRO, area_sqkm_low, pop_density_low, greater_20k, pop_total_x_pop_density, pop_total_x_area_sqkm, pop_density_X_area_sqkm)
```

Keeping greater_20k beause of previous insights about 


### Data splitting - Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_ml_final$dea_robust |> 
  createDataPartition(p = 0.75, list = FALSE)

train.data  <- df_ml_final[training.samples, ]
test.data <- df_ml_final[-training.samples, ] 
```

### Training Random Forest

```{r}
ctrl <- trainControl(method = "cv", number = 5)

set.seed(3456)
rf_tune_final <- train(dea_robust ~., 
                 data = train.data,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 1000,
                 tuneGrid = data.frame(mtry= c(53)), # found to be best tune
                 importance = TRUE)
```

Show R² of best model to show is not overfitting
```{r}
rf_tune_final$finalModel$importance

summary(rf_tune_final$finalModel)

plot(rf_tune_final)

rf_tune_final_n$bestTune

rf_tune_final_n$results
```

RMSE was used to select the optimal model using the smallest value.
The final value used for the model was mtry = 55.

```{r}
model_results <- data.frame(dea_robust = test.data$dea_robust)
model_results$rf <- predict(rf_tune_final, test.data)

# to store model performance metrics
performance_metrics_rf <- postResample(pred = model_results$rf, obs = model_results$dea_robust)
performance_metrics_rf
model_performance <- data.frame(performance_metrics_rf)
```
### Training Extreme Gradian Boosting

```{r}
ctrl <- trainControl(method = "cv", number = 5)

tune_grid <- expand.grid(
  nrounds = c(1500),
  max_depth = c(10),
  eta = c(0.005),
  gamma = c(0.000001),
  colsample_bytree = c(0.8),
  min_child_weight = c(5),
  subsample = c(0.7)
)

set.seed(123)
xgb_tune <- train(dea_robust ~., 
                  data = train.data,
                  method = "xgbTree",
                  preProc=c('scale','center'),
                  trControl = ctrl,
                  tuneGrid = tune_grid)
```

```{r}
model_results$xg_boost <- predict(xgb_tune, test.data)
performance_metrics_xgb <- postResample(pred = model_results$xg_boost,  obs = model_results$dea_robust)
performance_metrics_xgb
model_performance <- cbind(data.frame(model_performance, performance_metrics_xgb))
```


```{r}
xgb_tune$results

varImp(xgb_tune)
```

Results
eta   max_depth gamma colsample_bytree min_child_weight subsample nrounds RMSE Rsquared   MAE
0.005	10	0.001	0.8	5	0.7	1500	0.03982445	0.6859576   0.03032696

### Training Catboost

```{r}
ctrl <- trainControl(method = "cv", number = 5)
```

```{r}
# Specify the features and the target
features <- names(df_ml_final)[names(df_ml_final) != "dea_robust"]
target <- "dea_robust"

# Convert data to catboost pool
train_pool <- catboost.load_pool(data = train.data[, features], label = train.data[[target]])
test_pool <- catboost.load_pool(data = test.data[, features],label = test.data[[target]])

fit_params <- list(iterations = 300,
                   learning_rate = 0.1,
                   depth = 10,
                   loss_function = 'RMSE',
                   l2_leaf_reg = 20,
                   use_best_model = TRUE,
                   od_type = "Iter")

# Train the CatBoost model
catboost_tune <- catboost.train(train_pool, params = fit_params, test_pool = test_pool)
```
Performance on test set

```{r}
# Make predictions on the test data
pred <- catboost.predict(catboost_tune, test_pool)
model_results$catboost <- pred

# storing it in model performance table
performance_metrics_cat <- postResample(pred = model_results$catboost, obs = model_results$dea_robust)
performance_metrics_cat
model_performance <- cbind(data.frame(model_performance, performance_metrics_cat))
```

### In Text - Model selection

```{r}
model_performance
```

```{r}
qplot(model_results$xg_boost, model_results$dea_robust) + 
  labs(title="XGB Regression Observed VS Predicted (All Data)", x="Predicted", y="Observed") +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  theme_bw()
```


## Interpretation

### Under and overachievers

1. Step: Getting prediction information into main data frame

```{r}
# Predictions for train data using xgb_tune
predictions_test <- predict(xgb_tune, test.data)

# Create df_achievement_train with INE, NOMBRE, dea_robust
# Use training.samples from splitting data to correctly attach prediction data
df_achievement_test <- cbind(df_model_imp[-training.samples, ], predictions_test)
df_achievement <- 
  df_achievement_test |> 
  rename(predictions = predictions_test)
```

```{r}
yhat = df_achievement$predictions
y = df_achievement$dea_robust
error = y-yhat
noise <- error[1:100]

lwr <- yhat[101:length(yhat)] + quantile(noise,0.05, na.rm=T)
upr <- yhat[101:length(yhat)] + quantile(noise,0.95, na.rm=T)

predictions = data.frame(real=y[101:length(y)], fit=yhat[101:length(yhat)], lwr=lwr, upr=upr)

predictions = predictions %>% mutate(out=factor(if_else(real<lwr | real>upr,1,0)),
                                     o_u_achiever = factor(case_when(real < lwr ~ "underachiever",
                                                                     real > upr ~ "overachiever",
                                                                     TRUE ~ "as predicted")))

mean(predictions$out==1)
```

#### In Text - Prediction Interval

```{r}
Figure_8 <- 
  ggplot(predictions, aes(x=fit, y=real))+
  geom_point(aes(color=out)) + theme(legend.position="none") +
  geom_ribbon(data=predictions,aes(ymin=lwr,ymax=upr),alpha=0.3) +
  labs(x = "Predicted Efficiency",y="Recorded Efficiency") +
  scale_x_continuous(labels = scales::label_percent(), breaks = seq(0.60, 0.95, 0.05))+
  scale_y_continuous(labels = scales::label_percent(), breaks = seq(0.60, 1, 0.05))+
  theme_minimal() +
  theme(legend.position = "none") +
  scale_color_manual(values = c("#FF0000", "steelblue")) +
  annotate("text", x = 0.7, y = 0.95, label = "Overachiever", angle = 0, hjust = 1, color = "black", size = 3) + # overachiever
  geom_segment(aes(x = 0.7 , y = 0.948, xend = 0.748, yend = 0.925))+
  annotate("text", x = 0.85, y = 0.6, label = "Underachiever", angle = 0, hjust = 0, color = "black", size = 3) + # underachiever
  geom_segment(aes(x = 0.85 , y = 0.6, xend = 0.8009, yend = 0.655))+
  annotate("text", x = 0.65, y = 0.8, label = "As predicted", angle = 0, hjust = 1, color = "black", size = 3) + # as predicted
  geom_segment(aes(x = 0.65 , y = 0.8, xend = 0.675, yend = 0.737))

Figure_8
```

```{r}
ggsave(plot = Figure_8,"Data_2020/Figures/Figure_8.png", bg = "white", dpi = 300, width = 10, height = 7)
```

#### In Appendix - Names of Over and underachievers

Putting information on how municipalities fared into one data frame
```{r}
df_achievement_subset <- df_achievement[101:nrow(df_achievement), ]

predictions_subset <- predictions[c("out", "o_u_achiever")]

df_achievement <- cbind(df_achievement_subset, predictions_subset)

unique(df_achievement$NOMBRE[df_achievement$o_u_achiever == "overachiever"])
```


```{r}
unique(df_achievement$NOMBRE[df_achievement$o_u_achiever == "underachiever"])
```

### In Text - Variable importance

Creating my own plot for consistency

```{r}
var_imp <- varImp(xgb_tune)

# Convert the variable importance data to a data frame
var_imp_df <- as.data.frame(var_imp$importance)
var_imp_df$Variables <- rownames(var_imp_df)

unique(var_imp_df$Variables)


# renamed labels of first thirty variables
new_labels <- c(
  "share_ccaa_security_3" = "Share of Security Spending in CCAA (^3)",
  "share_ccaa_general_services" = "Share of General Services Spending in CCAA",
  "share_ue_agriculture_log" = "Share of Unemployed from Agriculture Sector (Log)",
  "pop_share_foreigners" = "Share of Foreigners in Population",
  "ue_pct_2020_log" = "Unemployment Percentage 2020 (Log)",
  "pop_share_wk_age_log" = "Share of Working Age Population (Log)",
  "pop_share_youth_log" = "Share of Youth (Log)",
  "share_contracts_agri" = "Share of New Contracts in Agriculture Sector",
  "per_capita_contracts_log" = "Average New Contracts per Capita and Month (Log)",
  "pop_density_log" = "Population Density (Log)",
  "revenue_grants_share_3" = "Share of Revenue from Grants (^3)",
  "share_ccaa_economic_log" = "Share of Economic Spending in CCAA (Log)",
  "share_ccaa_general_services_2" = "Share of General Services Spending in CCAA (Log)",
  "pop_total_x_pop_density" = "Population Total x Density",
  "employment_promotion" = "Share of Employment Promotion Spending",
  "share_ue_industry" = "Share of Unemployment from Industry Sector",
  "share_ue_construction_log" = "Share of Unemployment from Construction Sector (Log)",
  "general_services_2" = "Share of General Services Spending (^2)",
  "share_firms_service_log" = "Share of Firms in Service Sector (Log)",
  "share_contracts_serv_3" = "Share of New Contracts per Capita and Month in Service Sector",
  "pop_density_X_area_sqkm" = "Population Density x Area (in SQKM)",
  "share_ue_wo_job_log" = "Share of Unemployed without a Prior Job (Log)",
  "housing_urban_plan_3" = "Share of Housing and Urban Planning Spending (^3)",
  "revenue_other_share_log" = "Share of Revenue from Different Sources (Log)",
  "area_sqkm_3" = "Area in SQKM (^3)",
  "social_services" = "Share of Social Services Spending",
  "pop_total_x_area_sqkm" = "Population Total x Area (in SQKM)",
  "gov_bodies_log" = "Share of Government Bodies Spending (Log)",
  "environment_log" = "Share of Environment Spending (Log)"
)

# Plot showing first thirty variables
Figure_9 <- 
  var_imp_df |>
  filter(Overall > 3.25) |> 
  ggplot(aes(x = reorder(Variables, Overall), y = Overall)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(x = "", y = "Variable Importance") +
  theme_minimal()+
  theme(plot.title = element_text(hjust = 5.3))+ 
  scale_x_discrete(labels = new_labels)

Figure_9
```

```{r}
ggsave(plot = Figure_9,"Data_2020/Figures/Figure_9.png", bg = "white", width = 10, height = 7, dpi = 300)
```

### PDP

#### In Text Policy-related Plots

```{r}
# employment promotion
partial_plot_emp <- partial(xgb_tune, pred.var = "employment_promotion", plot = FALSE, rug = TRUE, train = train.data)
# Graph
p1 <- 
  ggplot(partial_plot_emp, aes(x = employment_promotion, y = yhat)) +
  geom_line(color = "steelblue") +
  labs(x = "Budget Share for Employment Promotion",
       y = "Predicted Efficiency Score") +
  theme_minimal() +
  theme(axis.ticks = element_blank(),
        axis.title.x = element_text(size = 10),
        axis.title.y = element_text(size = 10)) + 
  scale_x_continuous(breaks = seq(0, max(partial_plot_emp$employment_promotion), by = 5), minor_breaks = NULL,  labels = scales::label_percent(scale = 1))+
  scale_y_continuous(labels = scales::label_percent())

# General services
partial_plot_gen <- partial(xgb_tune, pred.var = "general_services_2", plot = FALSE, rug = TRUE, train = train.data)
# Graph
p2 <- 
  ggplot(partial_plot_gen, aes(x = general_services_2, y = yhat)) +
  geom_line(color = "steelblue") +
  labs(x = "Budget Share for General Services (²)",
       y = "Predicted Efficiency Score") +
  theme_minimal()+
  theme(axis.title.x = element_text(size = 10),
        axis.title.y = element_text(size = 10))+ 
  scale_y_continuous(labels = scales::label_percent())

# General services
partial_plot_soc <- partial(xgb_tune, pred.var = "social_services", plot = FALSE, rug = TRUE, train = train.data)
# Graph
p3 <- 
  ggplot(partial_plot_soc, aes(x = social_services, y = yhat)) +
  geom_line(color = "steelblue") +
  labs(x = "Budget Share for Social Services",
       y = "Predicted Efficiency Score") +
  theme_minimal() +
  theme(axis.ticks = element_blank(),
        axis.title.x = element_text(size = 10),
        axis.title.y = element_text(size = 10)) + 
  scale_x_continuous(breaks = seq(0, max(partial_plot_soc$social_services), by = 10), minor_breaks = NULL, labels = scales::label_percent(scale = 1)) +
  scale_y_continuous(labels = scales::label_percent())

# Environmental spending
partial_plot_grants <- partial(xgb_tune, pred.var = "revenue_grants_share_3", plot = FALSE, rug = TRUE, train = train.data)
# Graph
p4 <- 
  ggplot(partial_plot_grants, aes(x = revenue_grants_share_3, y = yhat)) +
  geom_line(color = "steelblue") +
  labs(x = "Share of Revenue from Grants (³)",
       y = "Predicted Efficiency Score") +
  theme_minimal() +
  theme(axis.ticks = element_blank(),
        axis.title.x = element_text(size = 10),
        axis.title.y = element_text(size = 10)) +
  scale_y_continuous(labels = scales::label_percent())
```

```{r}
Figure_10 <- p1 + p2 + p3 + p4

Figure_10
```

```{r}
ggsave(plot = Figure_10, "Data_2020/Figures/Figure_10.png", width = 10, height = 7, dpi = 300, bg = "white")
```

#### In Appendix - General Services and Pop Total

```{r}
Figure_B8 <- 
  ggplot(df_mae) +
    geom_point(aes(x = general_services, y = pop_total)) +
  labs(x = "Budget Share General Services", 
       y = "Total Population") +
  theme_minimal() +
  coord_cartesian( ylim = c(0, 50000)) +
  scale_x_continuous(breaks = seq(0, 100, by = 10), minor_breaks = NULL, labels = scales::label_percent(scale = 1))

Figure_B8
```
```{r}
ggsave(plot = Figure_B8, "Data_2020/Figures/Figure_B8.png", dpi = 300, bg = "white", width = 10, height = 7)
```


#### In Text - Structural-related predictors

```{r}
# employment promotion
partial_plot_sec_ccaa <- partial(xgb_tune, pred.var = "share_ccaa_security_3", plot = FALSE, rug = TRUE, train = train.data)
# Graph
p5 <- 
  ggplot(partial_plot_sec_ccaa, aes(x = share_ccaa_security_3, y = yhat)) +
  geom_line(color = "steelblue") +
  labs(x = "Budget Share CCAA Security (³)",
       y = "Predicted Efficiency Score") +
  theme_minimal() +
  theme(axis.ticks = element_blank(),
        axis.title.x = element_text(size = 10),
        axis.title.y = element_text(size = 10))+
  scale_y_continuous(labels = scales::label_percent())

# General services
partial_plot_gen_ccaa <- partial(xgb_tune, pred.var = "share_ccaa_general_services", plot = FALSE, rug = TRUE, train = train.data)
# Graph
p6 <- 
  ggplot(partial_plot_gen_ccaa, aes(x = share_ccaa_general_services, y = yhat)) +
  geom_line(color = "steelblue") +
  labs(x = "Budget Share CCAA General Services",
       y = "Predicted Efficiency Score") +
  theme_minimal() +
  theme(axis.ticks = element_blank(),
        axis.title.x = element_text(size = 10),
        axis.title.y = element_text(size = 10))+
  scale_y_continuous(labels = scales::label_percent())

# General services
partial_plot_foreigners <- partial(xgb_tune, pred.var = "pop_share_foreigners", plot = FALSE, rug = TRUE, train = train.data)
# Graph
p7 <- 
  ggplot(partial_plot_foreigners, aes(x = pop_share_foreigners, y = yhat)) +
  geom_line(color = "steelblue") +
  labs(x = "Share of Foreigners",
       y = "Predicted Efficiency Score") +
  theme_minimal() +
  theme(axis.ticks = element_blank(),
        axis.title.x = element_text(size = 10),
        axis.title.y = element_text(size = 10))+
  scale_y_continuous(labels = scales::label_percent()) + 
  scale_x_continuous(breaks = seq(0, max(partial_plot_foreigners$pop_share_foreigners), by = 10), minor_breaks = NULL,  labels = scales::label_percent(scale = 1))

# Environmental spending
partial_plot_ue <- partial(xgb_tune, pred.var = "ue_pct_2020_log", plot = FALSE, rug = TRUE, train = train.data)
# Graph
p8 <- 
  ggplot(partial_plot_ue, aes(x = ue_pct_2020_log, y = yhat)) +
  geom_line(color = "steelblue") +
  labs(x = "Unemployment Percentage 2020 (log)",
       y = "Predicted Efficiency Score") +
  theme_minimal() +
  theme(axis.ticks = element_blank(),
        axis.title.x = element_text(size = 10),
        axis.title.y = element_text(size = 10)) +
  scale_y_continuous(labels = scales::label_percent())
```

```{r}
Figure_11 <- p5 + p6 + p7 + p8

Figure_11
```

```{r}
ggsave(plot = Figure_11,"Data_2020/Figures/Figure_11.png", width = 10, height = 7, dpi = 300, bg = "white")
```


### SHAP

#### Not Included - Importance Bee Plot

```{r}
X <- train.data[sample(nrow(train.data), 1000), -which(names(train.data) == "dea_robust")]
bg_X <- train.data[sample(nrow(train.data), 100), -which(names(train.data) == "dea_robust")]

s <- kernelshap(xgb_tune, X = X, bg_X = bg_X) 
sv <- shapviz(s)
sv_importance(sv, kind = "bee", max_display = Inf) +
  theme_minimal()
```

#### In Text - Dependence Plot - Structural Features

```{r}
SHAP_structural <- c("pop_share_foreigners", "ue_pct_2020_log", "pop_density_log")


customizations_structural <- list(
  list(
    legend_title = "Share of Unemployed\nfrom Agricultural Sector (log)",
    x_axis_label = "Share of Foreigners"

  ),
  list(
    legend_title = "Share of\nPopulationin Working Age (log)",
    x_axis_label = "Unemployment Rate (log)"

  ),
  list(
    legend_title = "Budget Share CCAA Security (³)",
    x_axis_label = "Population Density (log)"

  )
)

plots_structural <- lapply(seq_along(SHAP_structural), function(i) {
  var <- SHAP_structural[i]
  customizations_structural <- customizations_structural[[i]]
  
  plot <- sv_dependence(sv, v = var) + 
    theme_minimal() +
    labs(colour = customizations_structural$legend_title,
         x = customizations_structural$x_axis_label) +
    guides(colour = guide_colourbar(direction = "horizontal", title.position = "top"))
  
  return(plot)
})

# Display the first plot as an example
p9 <- 
  plots_structural[[1]] + 
  scale_x_continuous(breaks = seq(0, 65, by = 10), minor_breaks = NULL,  labels = scales::label_percent(scale = 1))


p10 <- 
  plots_structural[[2]]

p11 <- 
  plots_structural[[3]]


Figure_12 <- wrap_plots(p9, p10, p11, ncol = 1)

Figure_12
```

```{r}
ggsave(plot = Figure_12,"Data_2020/Figures/Figure_12.png", width = 10, height = 12, dpi = 300, bg = "white")
```

#### In Text - Dependence plots - Provinces

```{r}
SHAP_region <- "CPRO"
Figure_13 <- 
  sv_dependence(sv, v = SHAP_region) +
  theme_minimal()+
  guides(colour = guide_colourbar(direction = "horizontal", title.position = "top")) +
  labs(color = "Share of Youth (log)",
       x = "Province Codes")

Figure_13
```

```{r}
ggsave(plot = Figure_13,"Data_2020/Figures/Figure_13.png", dpi = 300, width = 12, height = 7, bg = "white")
```


#### In Text - Dependence Plots - Policy Features

```{r}
SHAP_policy <- c("employment_promotion", "environment_log","social_services","general_services_2")

customizations_policy <- list(
  list(
    legend_title = "Share of Unemployed\nfrom Agricultural Sector (log)",
    x_axis_label = "Budget Share Employment Promotion"

  ),
  list(
    legend_title = "Share of Contracts\nin Agricultural Sector",
    x_axis_label = "Budget Share Environment (log)"

  ),
  list(
    legend_title = "Share of Contracts\nin Agricultural Sector",
    x_axis_label = "Budget Share Social Services"

  ),
  list(
    legend_title = "Share of Contracts\nin Construction Sector (log)",
    x_axis_label = "Budget Share General Services (²)"

  )
)

plots_policy <- lapply(seq_along(SHAP_policy), function(i) {
  var <- SHAP_policy[i]
  customizations_policy <- customizations_policy[[i]]
  
  plot <- sv_dependence(sv, v = var) + 
    theme_minimal() +
    labs(colour = customizations_policy$legend_title,
         x = customizations_policy$x_axis_label) +
    guides(colour = guide_colourbar(direction = "horizontal", title.position = "top"))
  
  return(plot)
})


p12 <- 
  plots_policy[[1]] + 
  scale_x_continuous(breaks = seq(0, 50, by = 10), minor_breaks = NULL,  labels = scales::label_percent(scale = 1))

p13 <- 
  plots_policy[[2]]

p14 <- 
  plots_policy[[3]] + 
  scale_x_continuous(breaks = seq(0, 50, by = 10), minor_breaks = NULL,  labels = scales::label_percent(scale = 1))

p15 <- 
  plots_policy[[4]] 

Figure_14 <- p12 + p13 + p14 + p15

Figure_14
```

```{r}
ggsave(plot = Figure_14,"Data_2020/Figures/Figure_14.png", width = 14, height = 10, dpi = 300, bg = "white")
```


## Appendix 

### Historical Unemployment Rate Development

```{r}
# Read the file line by line
lines <- readLines("Data_2020/world_ue_data.csv", encoding = "UTF-8")

# Extract column names from the third line
column_names <- unlist(strsplit(lines[5], ",", fixed = TRUE))
column_names <- gsub('"', "", column_names)  # Remove quotes
column_names <- gsub("\\\\", "", column_names)

# to shift columns one column to the right
column_names <- c("country_name", column_names)


# Split each line into columns based on commas
data <- lapply(lines[-(1:5)], function(line) {
  unlist(strsplit(line, ",", fixed = TRUE))
})

# Convert the list to a data frame and assign column names
data <- as.data.frame(do.call(rbind, data))
names(data) <- column_names


Figure_1 <- 
  data |> 
  select("country_name","1990":"2021") |> 
  mutate(across("1990":"2021", ~str_extract(., "\\d+\\.?\\d*"))) |> 
  filter(country_name == '"Spain') |> 
  pivot_longer(cols = "1990":"2021",
               values_to = "ue_rate",
               names_to = "year") |> 
  mutate(ue_rate = as.numeric(ue_rate)/100,
         year = as.Date(paste0(year, "-01-01"))) |> 
  ggplot()+
  geom_line(aes(x = year, y = ue_rate), colour = "steelblue") +
  geom_vline(xintercept = as.Date("2007-02-01"), linetype = "dashed", color = "black") + # begin o great recession
  annotate("text", x = as.Date("2004-07-01"), y = 0.23, label = "Begin of the\nGreat Recession", angle = 0, hjust = 1, color = "black", size = 3) + 
  geom_segment(aes(x = as.Date("2007-02-01"), y = 0.23, xend = as.Date("2004-08-01"), yend = 0.23)) +
  geom_vline(xintercept = as.Date("2012-12-01"), linetype = "dashed", color = "black") + # End of Eurozone crisis
  annotate("text", x = as.Date("2014-12-20"), y = 0.1, label = "End of the\nEurozone Crisis", angle = 0, hjust = 0, color = "black", size = 3) + 
  geom_segment(aes(x = as.Date("2012-12-01"), y = 0.1, xend = as.Date("2014-12-01"), yend = 0.1)) +
  geom_vline(xintercept = as.Date("2019-05-01"), linetype = "dashed", color = "black") + # Start of covid
  annotate("text", x = as.Date("2018-01-01"), y = 0.25, label = "Begin of Covid-19\nPandemic", angle = 0, hjust = 1, color = "black", size = 3) + 
  geom_segment(aes(x = as.Date("2019-05-01"), y = 0.23, xend = as.Date("2018-01-01"), yend = 0.25)) + 
  labs(y = "Share (%)",
       x = "") +
  scale_y_continuous(labels = scales::label_percent()) +
  scale_x_date(date_labels = "%Y", breaks = "1 year", expand = c(0, 0))+ 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  annotate(
    geom = "rect",
    xmin = as.Date("2007-02-10"), xmax = as.Date("2012-12-01"),
    ymin = -Inf, ymax = Inf,
    alpha = 0.5, fill = "grey"
  )+
  annotate(
    geom = "rect",
    xmin = as.Date("2019-05-10"), xmax = as.Date("2021-12-31"),
    ymin = -Inf, ymax = Inf,
    alpha = 0.5, fill = "grey"
  )

Figure_1
```

```{r}
ggsave(plot = Figure_1,"Data_2020/Figures/Figure_1.png", dpi = 300, bg = "white", width = 10, height = 7)
```

### Visualizing missing municipalities

Where is the difference

```{r}
m <-
  df_dea |>
  mutate(CODAUTO_data = CODAUTO) |> 
  group_by(CODAUTO_data, CCAA) |> 
  distinct(INE) |> 
  count(CODAUTO_data)
# adding missing community 
new_row <- data.frame(CODAUTO_data = c("18","19"), CCAA = c("Melilla", "Ceuta"),n = c(0, 0))
m <- m |> 
  bind_rows(new_row)

# reading municipality declaration data
codigo_municipio <- read_excel("Data_2020/diccionario24.xlsx", skip = 1, col_names = TRUE) |> 
  mutate(INE = paste0(CPRO, CMUN),
         Provincia = as.integer(CPRO))

o <- 
  codigo_municipio |>
  mutate(CODAUTO_original = CODAUTO) |> 
  group_by(CODAUTO_original) |> 
  distinct(INE) |> 
  count(CODAUTO_original)

difference_n_mun <- o |> 
  left_join(m, by = c("CODAUTO_original"= "CODAUTO_data")) |> 
  mutate(difference = n.x - n.y,
         proportion = (difference/n.x)*100)

Figure_B1 <- 
  difference_n_mun |> 
  filter(!CCAA == "Ceuta" & !CCAA == "Melilla") |> 
  ggplot()+
  geom_col(aes(CCAA, proportion), fill = "steelblue") +
  geom_text(aes(CCAA, proportion, label = paste(round(proportion, 2),"%")),
            vjust = -0.4,
            size = 2.5) + 
  scale_y_continuous(labels = (scales::label_percent(scale = 1))) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(y = "Share (%)",
       x = "")

Figure_B1
```

```{r}
ggsave(plot = Figure_B1, "Data_2020/Figures/Figure_B1.png", dpi = 300, width = 10, height = 7, bg = "white")
```


### Data summary

```{r}
summary_df <- psych::describe(df_summary)

summary_df$variable <- rownames(summary_df)
summary_df <- summary_df[, c("variable", colnames(summary_df)[1:(ncol(summary_df)-1)])]

summary_df <- summary_df[, !colnames(summary_df) %in% c("trimmed", "mad", "skew", "kurtosis")]

ft <- flextable(summary_df)
ft <- set_caption(ft, caption = "Summary Statistics of df_summary")

ft <- theme_vanilla(ft) |> 
  autofit() |> 
  set_table_properties(width = 0.8, layout = "autofit") |> # smaller table
  align(j = 2:ncol(summary_df), align = "center", part = "all") |>   # Center text in all columns except the first
  colformat_double(j = 2:ncol(summary_df), digits = 2) |>  # Format numbers to 2 decimal places
  fontsize(size = 8, part = "all") 

doc <- read_docx()

# Add the flextable to the Word document
doc <- body_add_flextable(doc, value = ft)

# Save the Word document
print(doc, target = "Data_2020/Tables/summary_table.docx")
```

### Template

```{r}
# Create an empty data frame with the same structure but 6 rows
empty_df <- summary_df[1:6, ]
empty_df[] <- NA  # Fill the data frame with NA to make it empty

# Create a flextable from the empty data frame
ft_empty <- flextable(empty_df)

# Customize the flextable for better readability
ft_empty <- ft_empty %>%
  theme_vanilla() %>%
  autofit() %>%
  set_table_properties(width = 0.8, layout = "autofit") %>%
  align(j = 2:ncol(empty_df), align = "center", part = "all")

# Create a new Word document
doc_empty <- read_docx()

# Add the empty flextable to the new Word document
doc_empty <- body_add_flextable(doc_empty, value = ft_empty)

# Save the new Word document
print(doc_empty, target = "Data_2020/Tables/empty_template_table.docx")
```

