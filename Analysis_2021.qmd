---
title: "Analysis"
format: html
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Analysis

### Library

```{r}
options(scipen = 999)
library(devtools)
library(tidyverse)
library(readxl)
library(rDEA)
library(caret)
library(mice)
library(xgboost)
library(mapSpain)
library(kernelshap)
library(shapviz)
library(pdp)
```

### Load data (if needed)

```{r}
df_final <- read.csv("Data_2020/TFM_data_2024-06-05.csv", colClasses = c(INE = "character")) |> 
  select(-X)
```

### Data Envelopment Analysis

Ideas:

Unemployment as outcome Contracts as outcome (contracts per capita)

-   variables for DEA:

-   n_firms

-   per capita CCAA spending

-   per capita mun spending

-   distance

-   unemployment rate

-   variables for prediction task

    -   how money was spent
    -   population (absolute number)
    -   pop share foreigners
    -   pop share working age
    -   average age
    -   median income per household unit (?)
    -   contracts mean 2023
    -   greater 20k
    -   pop density

More idea - contracts divided by area (contracts database)

------------------------------------------------------------------------

In the context of Data Envelopment Analysis (DEA) and efficiency estimation, censoring refers to the phenomenon where efficiency scores are bounded or capped at a certain value. This means that despite variations in input-output combinations among decision-making units (DMUs), a substantial number of DMUs are assigned the maximum efficiency score (often 1) by the DEA model.

When efficiency scores are "censored," it implies that the DEA model is unable to distinguish between highly efficient DMUs, resulting in a clustering of efficiency scores at the upper bound (e.g., 1). This can occur due to various factors such as data limitations, measurement errors, model assumptions, or the inherent characteristics of the production process being analyzed.

------------------------------------------------------------------------

Taking the inverse of unemployment because output oriented DEA defines higher values as better

Using per capita spending on CCAA level and distance from provincial capital as environmental variables

Variable Returns to Scale (RTS = "Variable"): This assumption allows for flexibility in the relationship between inputs and outputs. It recognizes that the impact of municipal spending on reducing unemployment may vary across municipalities due to factors such as local economic conditions, labor market dynamics, and policy effectiveness.

## DEA

### Isotonocity 

check if vairiables are positively correlated

```{r}
X <- df_final[c("n_firms", "per_capita_MUN")]

Y <- df_final[c("target", "median_inc_con_unit")]
Y <- 
  Y |> 
  mutate(target = (target * -1)+100)

Z <- df_final[c("dist_prov_cap", "per_capita_CCAA")]



# Mean normalization function
mean_normalize <- function(x) {
  return((x - mean(x)) / (max(x) - min(x))+1)
}

# Apply mean normalization to each column
X <- X |>  mutate(across(everything(), mean_normalize))

Z <- Z |>  mutate(across(everything(), mean_normalize))

Y <- Y |> mutate(across(everything(), mean_normalize))
```



### Efficiency score estimation

```{r}
dea_robust <- 
  dea.env.robust(X, Y, W=NULL, Z, model="output", RTS="variable",
                L1=10, L2=100, alpha=0.05)
```

Calculating the efficiency score

```{r}
sorted_scores <- sort(dea_robust$delta_hat_hat, decreasing = TRUE)
best_score <- max(sorted_scores)
delta_hat_hat <- dea_robust$delta_hat_hat

df_dea <- 
  df_final |> 
  mutate(dea_robust = delta_hat_hat/best_score) 
```

## Descriptive Analysis

### Efficiency score

```{r}
df_dea |> 
  ggplot()+
  geom_histogram(aes(dea_robust), stat = "bin", bins = 160)
```

#### Most efficient municipalities

```{r}
df_dea |> 
  filter(dea_robust == 1) |> 
  count()
```

```{r}
df_dea |> 
  filter(dea_robust == 1)
```

#### Mean efficiency score

```{r}
mean(df_dea$dea_robust)
```

7808061

#### t-test between city sizes

```{r}
greater_20k <- df_dea[df_dea$greater_20k == 1, "dea_robust"]
smaller_20k <- df_dea[df_dea$greater_20k == 0, "dea_robust"]

# Perform the t-test
t_test_result <- t.test(greater_20k, smaller_20k)
t_test_result
```

Smaller municipalities are more efficient

```{r}
greater_100k <- df_dea[df_dea$pop_total > 100000, "dea_robust"]
smaller_100k <- df_dea[df_dea$pop_total <= 100000, "dea_robust"]

# Perform the t-test
t_test_result <- t.test(greater_100k, smaller_100k)
t_test_result
```

a bit more pronounced

### Correlation - robust

```{r}
df_corr <-
  df_dea |> 
  select(-c(INE, NOMBRE, dea_robust)) |>
  select_if(is.numeric)

corr<- cor(df_model_robust$dea_robust, df_corr, method = "spearman")
corr<-round(corr,4)

df_corr_results <- 
  data.frame(corr) |> 
  pivot_longer(values_to = "correlation",
               cols = 1:61,
               names_to = "variable")

ggplot(df_corr_results, aes(x = variable, y = correlation)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Correlation with DEA efficiency score", x = "Variable", y = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) 
```

### Unemployment change
#### Map


### Median income
#### Map

## Feature Selection and Engineering

### Deleting unnsecessary variables

All variables without additional meaning and variables used in estimating efficiency score+

No revenue data - resembles spending data

delted this revenue data:
per_capita_revenue,

also deleted population (too little information)
, pop_smaller_5k, pop_5k_to_20k, pop_20k_to_50k, pop_50k_above

deleted because of ideology scores
 party_mun, party_ccaa

```{r}
df_model <- 
  df_dea |> 
  select(-c(CODAUTO, total_CCAA, total_MUN, target, dist_prov_cap, per_capita_CCAA, per_capita_MUN, n_firms, contracts_mean_2020, median_inc_con_unit, per_capita_revenue, party_mun, party_ccaa))
```

Data chosen I
, share_essential_business, share_essential_employment, per_capita_ccaa_general_services,per_capita_ccaa_security, per_capita_ccaa_economic, per_capita_ccaa_housing_services, per_capita_ccaa_culture, per_capita_ccaa_social_protection

Data chosen II
share_ccaa_general_services, share_ccaa_security, share_ccaa_economic, share_ccaa_housing_services, share_ccaa_culture, share_ccaa_social_protection


### DELETE category Adjusting party data 

for statistical information

```{r}
zero_var_levels <- names(table(df_model$party_mun))[table(df_model$party_mun) == 0]
print(zero_var_levels)
```

## Data imputation

```{r}
m <- 5
set.seed(475)
imp <- mice(df_model, m = m, method= "rf")
df_model_imp <- complete(imp, action=m)
```

## Preliminary


```{r}
df_model_robust <- df_model_imp |> 
  select(-c(INE, NOMBRE, CCAA, CPRO)) 
```

excluded:
|> 
  filter(!is.na(party_mun)) |> 
  drop_na()
  

## Modelling - Target normal - Random forest

### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train(dea_robust ~ .,
                     data = df_model_robust,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```

#### Data chosen I - CCAA per capita

[1] "party_munOTROS"                    "party_munPSOE"                     "party_munN.ADS."                  
 [4] "party_munUCIN"                     "party_munAxSI"                     "party_munBNG"                     
 [7] "party_munPAR"                      "party_munUPL"                      "party_ccaaERC"                    
[10] "party_ccaaPNV"                     "party_ccaaPSOE"                    "general_services"                 
[13] "environment"                       "social_services"                   "agr_farm_fish"                    
[16] "tax_fin_admin"                     "public_debt"                       "health"                           
[19] "education"                         "infrastructure"                    "employment_promotion"             
[22] "sports"                            "pub_transportation"                "area_sqkm"                        
[25] "ue_pct_2020"                       "pop_share_foreigners"              "pop_share_wk_age"                 
[28] "pop_share_retirees"                "share_essential_business"          "share_essential_employment"       
[31] "rural_prop_tax"                    "special_prop_tax"                  "min_coef_turn_tax"                
[34] "per_capita_ccaa_general_services"  "per_capita_ccaa_security"          "per_capita_ccaa_economic"         
[37] "per_capita_ccaa_culture"           "per_capita_ccaa_social_protection" "pop_density"                      
[40] "per_capita_contracts"              "revenue_tax_share"               

#### Data chosen II
[1] "party_munPP"                  "party_munOTROS"               "party_munPSOE"               
 [4] "party_munN.ADS."              "party_munUCIN"                "party_munAxSI"               
 [7] "party_munBNG"                 "party_munPAR"                 "party_munUPL"                
[10] "party_ccaaERC"                "party_ccaaPNV"                "party_ccaaPRC"               
[13] "party_ccaaPSOE"               "general_services"             "environment"                 
[16] "social_services"              "agr_farm_fish"                "tax_fin_admin"               
[19] "public_debt"                  "health"                       "education"                   
[22] "infrastructure"               "employment_promotion"         "sports"                      
[25] "pub_transportation"           "area_sqkm"                    "ue_pct_2020"                 
[28] "pop_share_foreigners"         "pop_share_wk_age"             "pop_share_retirees"          
[31] "share_essential_business"     "share_essential_employment"   "rural_prop_tax"              
[34] "special_prop_tax"             "min_coef_turn_tax"            "share_ccaa_general_services" 
[37] "share_ccaa_economic"          "share_ccaa_culture"           "share_ccaa_social_protection"
[40] "pop_density"                  "per_capita_contracts"         "revenue_tax_share" 

#### Data chosen III
 [1] "party_munPP"                  "party_munOTROS"               "party_munPSOE"                "party_munN.ADS."              "party_munUCIN"               
 [6] "party_munBNG"                 "party_munPAR"                 "party_munUPL"                 "party_ccaaERC"                "party_ccaaPNV"               
[11] "party_ccaaPSOE"               "general_services"             "environment"                  "social_services"              "agr_farm_fish"               
[16] "tax_fin_admin"                "public_debt"                  "health"                       "education"                    "infrastructure"              
[21] "employment_promotion"         "sports"                       "pub_transportation"           "pensions"                     "r_and_d"                     
[26] "area_sqkm"                    "ue_pct_2020"                  "share_ue_construction"        "share_ue_industry"            "share_ue_agriculture"        
[31] "share_ue_wo_job"              "pop_share_foreigners"         "pop_share_wk_age"             "pop_share_retirees"           "share_women"                 
[36] "share_essential_employment"   "share_firms_service"          "share_contracts_agri"         "share_contracts_con"          "rural_prop_tax"              
[41] "special_prop_tax"             "min_coef_turn_tax"            "revenue_tax_share"            "share_ccaa_general_services"  "share_ccaa_economic"         
[46] "share_ccaa_culture"           "share_ccaa_social_protection" "pop_density"                  "per_capita_contracts"    

#### Data chosen IV - Ideology score

 [1] "general_services"            "environment"                 "social_services"             "agr_farm_fish"               "tax_fin_admin"              
 [6] "public_debt"                 "health"                      "education"                   "infrastructure"              "employment_promotion"       
[11] "trans_public_agencies"       "other_econ"                  "pub_transportation"          "r_and_d"                     "area_sqkm"                  
[16] "ue_pct_2020"                 "share_ue_construction"       "share_ue_industry"           "share_ue_agriculture"        "pop_share_foreigners"       
[21] "pop_share_wk_age"            "pop_share_retirees"          "share_women"                 "share_essential_employment"  "share_firms_service"        
[26] "share_contracts_agri"        "share_contracts_con"         "rural_prop_tax"              "special_prop_tax"            "revenue_tax_share"          
[31] "revenue_grants_share"        "share_ccaa_general_services" "share_ccaa_security"         "share_ccaa_economic"         "share_ccaa_housing_services"
[36] "share_ccaa_culture"          "pop_density"                 "per_capita_contracts"        "ideology_score"  

```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "party")&!startsWith(non_zero_vars, "greater")]


df_model_final <- 
  df_model_imp |>
  dplyr::select(all_of(non_zero_vars), dea_robust, INE, NOMBRE)|>
  filter(!is.na(party_mun)) |> # remove if using ideology score
  drop_na()
# excluded , party_mun,party_ccaa for the moment

# all_of(non_zero_vars), dea_robust, greater_20k, party_mun, party_ccaa, INE, NOMBRE
```

Hypothesis: covid employment data makes models overfit --\> too accurate AND decreases R-squared. How?


#### Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_model_final$dea_robust |> 
  createDataPartition(p = 0.75, list = FALSE)

train.data  <- df_model_final[training.samples, ]
test.data <- df_model_final[-training.samples, ] 

# deleting INE and NOMBRE from train set to keep in test only
train.data$INE <- NULL
train.data$NOMBRE <- NULL

```

#### Training RF
```{r}
ctrl <- trainControl(method = "cv", number = 5)

set.seed(3456)
rf_tune <- train(dea_robust ~., 
                 data = train.data,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(12, 15, 18,21)),
                 importance = TRUE)

rf_tune$finalModel$importance

rf_tune$results

varImp(rf_tune)

plot(varImp(rf_tune))
```

##### Results

```{r}
test_results <- data.frame(dea_robust = test.data$dea_robust)
#normal
test_results$rf <- predict(rf_tune, test.data)
rf_normal <- postResample(pred = test_results$rf,  obs = test_results$dea_robust)
```

See data chosen I
0.6485436 
MAE
0.03261175

see data chosen I
Normal
 RMSE   Rsquared        MAE 
0.04348254 0.63551313 0.03342641 

Data chosen II
0.6504064
MAE
0.03264785

see data chosen II
Normal
      RMSE   Rsquared        MAE 
0.04340711 0.63832142 0.03360933 

Data chosen III
0.6552379
MAE
0.03280619
    RMSE   Rsquared        MAE 
0.04294293 0.64908921 0.03300969

Data chosen IV
0.6574947
MAE
0.03240815
   RMSE   Rsquared        MAE 
0.04262793 0.65125692 0.03257174 


--\> constant problem: overfitting (reduced with additional data)

-   **MAE Interpretation:** MAE (Mean Absolute Error) represents the average difference between the predicted values and the actual values. In your case, the average difference is only 0.034, which is a very small portion of the target variable's range (0.5 to 1).

-   **Relative Error:** Considering the limited range of the target variable (from 0.5 to 1), an absolute error of 0.034 is even more significant. It translates to a maximum relative error of around 6.8% (0.034 / (1-0.5) ).

**General Rule of Thumb:**

-   A lower MAE indicates better model performance. In general, an MAE less than 10% of the variable's range is considered good. Here, your MAE is well below that threshold.

Prediction

## Modelling - Target log - Random forest

### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train(log(dea_robust) ~ .,
                     data = df_model_robust,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```
#### Data chosen I
Did not do first two correctly

 [1] "party_munPP"                  "party_munOTROS"               "party_munPSOE"                "party_munN.ADS."              "party_munUCIN"               
 [6] "party_munBNG"                 "party_munPAR"                 "party_munUPL"                 "party_munAHORA DECIDE"        "party_ccaaERC"               
[11] "party_ccaaPNV"                "party_ccaaPSOE"               "general_services"             "environment"                  "social_services"             
[16] "culture"                      "agr_farm_fish"                "tax_fin_admin"                "public_debt"                  "health"                      
[21] "education"                    "infrastructure"               "employment_promotion"         "sports"                       "trans_public_agencies"       
[26] "pub_transportation"           "pensions"                     "r_and_d"                      "area_sqkm"                    "ue_pct_2020"                 
[31] "share_ue_construction"        "share_ue_industry"            "share_ue_agriculture"         "share_ue_wo_job"              "pop_share_foreigners"        
[36] "pop_share_wk_age"             "pop_share_retirees"           "share_women"                  "share_essential_employment"   "share_firms_service"         
[41] "share_contracts_agri"         "share_contracts_con"          "rural_prop_tax"               "special_prop_tax"             "min_coef_turn_tax"           
[46] "revenue_tax_share"            "share_ccaa_general_services"  "share_ccaa_economic"          "share_ccaa_culture"           "share_ccaa_social_protection"
[51] "pop_density"                  "per_capita_contracts"

#### Data chosen II - ideology score
 [1] "general_services"             "environment"                  "social_services"              "agr_farm_fish"                "tax_fin_admin"               
 [6] "public_debt"                  "health"                       "education"                    "infrastructure"               "employment_promotion"        
[11] "sports"                       "trans_public_agencies"        "other_econ"                   "pub_transportation"           "pensions"                    
[16] "r_and_d"                      "area_sqkm"                    "ue_pct_2020"                  "share_ue_service"             "share_ue_construction"       
[21] "share_ue_industry"            "share_ue_agriculture"         "pop_share_foreigners"         "pop_share_wk_age"             "pop_share_retirees"          
[26] "share_women"                  "share_essential_employment"   "share_firms_service"          "share_contracts_agri"         "share_contracts_con"         
[31] "urban_prop_tax"               "rural_prop_tax"               "special_prop_tax"             "min_coef_turn_tax"            "revenue_tax_share"           
[36] "revenue_grants_share"         "share_ccaa_general_services"  "share_ccaa_security"          "share_ccaa_economic"          "share_ccaa_housing_services" 
[41] "share_ccaa_culture"           "share_ccaa_social_protection" "pop_density"                  "per_capita_contracts"         "ideology_score" 

```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "party")&!startsWith(non_zero_vars, "greater")]


df_model_final <- 
  df_model_imp |>
  dplyr::select(all_of(non_zero_vars), dea_robust, INE, NOMBRE)|>
  drop_na()
# excluded , party_mun,party_ccaa for the moment
```

filter(!is.na(party_mun)) |> 


#### Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_model_final$dea_robust |> 
  createDataPartition(p = 0.75, list = FALSE)

train.data  <- df_model_final[training.samples, ]
test.data <- df_model_final[-training.samples, ] 

# deleting INE and NOMBRE from train set to keep in test only
train.data$INE <- NULL
train.data$NOMBRE <- NULL

```

#### Training RF
```{r}
ctrl <- trainControl(method = "cv", number = 5)

set.seed(3456)
rf_tune_log <- train(log(dea_robust) ~., 
                 data = train.data,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(9,12,15,18,21)),
                 importance = TRUE)

rf_tune_log$finalModel$importance

rf_tune_log$results

varImp(rf_tune_log)

plot(varImp(rf_tune_log))
```

##### Results

```{r}
# log
test_results$rf_log <- predict(rf_tune_log, test.data)
test_results$rf_log <- exp(test_results$rf_log)
rf_log <- postResample(pred = test_results$rf_log,  obs = test_results$dea_robust)
```
see data chosen I
0.6648428
MAE
0.04230489
    RMSE  Rsquared       MAE 
1.0353495 0.6472887 1.0344253

data chosen II
0.6637780
MAE
0.04170904
 RMSE   Rsquared        MAE 
0.04204950 0.66050201 0.03215307 

## Modelling - Target log10 - Random forest
### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train(log10(dea_robust) ~ .,
                     data = df_model_robust,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```
#### Data chosen I
Did not do first two correctly

[1] "party_munPSOE"                "party_munPAR"                 "party_ccaaERC"                "party_ccaaPNV"                "party_ccaaPSOE"              
 [6] "environment"                  "social_services"              "agr_farm_fish"                "tax_fin_admin"                "public_debt"                 
[11] "health"                       "infrastructure"               "employment_promotion"         "pub_transportation"           "area_sqkm"                   
[16] "ue_pct_2020"                  "share_ue_construction"        "share_ue_industry"            "share_ue_agriculture"         "pop_share_foreigners"        
[21] "pop_share_wk_age"             "pop_share_retirees"           "share_women"                  "share_essential_employment"   "share_firms_service"         
[26] "share_contracts_agri"         "share_contracts_con"          "rural_prop_tax"               "special_prop_tax"             "revenue_tax_share"           
[31] "revenue_grants_share"         "share_ccaa_general_services"  "share_ccaa_security"          "share_ccaa_economic"          "share_ccaa_culture"          
[36] "share_ccaa_social_protection" "pop_density"                  "per_capita_contracts" 

data chosen II
[1] "environment"                 "social_services"             "agr_farm_fish"               "tax_fin_admin"               "public_debt"                
 [6] "health"                      "infrastructure"              "employment_promotion"        "pub_transportation"          "area_sqkm"                  
[11] "ue_pct_2020"                 "share_ue_construction"       "share_ue_industry"           "share_ue_agriculture"        "pop_share_foreigners"       
[16] "pop_share_wk_age"            "pop_share_retirees"          "share_women"                 "share_essential_employment"  "share_firms_service"        
[21] "share_contracts_agri"        "share_contracts_con"         "rural_prop_tax"              "special_prop_tax"            "revenue_tax_share"          
[26] "revenue_grants_share"        "share_ccaa_general_services" "share_ccaa_security"         "share_ccaa_economic"         "share_ccaa_housing_services"
[31] "share_ccaa_culture"          "pop_density"                 "per_capita_contracts"

```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "party")&!startsWith(non_zero_vars, "greater")]


df_model_final <- 
  df_model_imp |>
  dplyr::select(all_of(non_zero_vars), dea_robust, INE, NOMBRE)|> 
  drop_na()
# excluded party ccaa for the moment
```

Hypothesis: covid employment data makes models overfit --\> too accurate AND decreases R-squared. How?

|> 
  filter(!is.na(party_mun)) 

#### Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_model_final$dea_robust |> 
  createDataPartition(p = 0.75, list = FALSE)

train.data  <- df_model_final[training.samples, ]
test.data <- df_model_final[-training.samples, ] 

# deleting INE and NOMBRE from train set to keep in test only
train.data$INE <- NULL
train.data$NOMBRE <- NULL

```

#### Training RF
```{r}
ctrl <- trainControl(method = "cv", number = 5)

set.seed(3456)
rf_tune_log10 <- train(log10(dea_robust) ~., 
                 data = train.data,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(9,12,15,18,21)),
                 importance = TRUE)

rf_tune_log10$finalModel$importance

rf_tune_log10$results

varImp(rf_tune_log10)

plot(varImp(rf_tune_log10))
```

##### Results

```{r}
# log10
test_results$rf_log10 <- predict(rf_tune_log10, test.data)
test_results$rf_log10 <- 10^(test_results$rf_log10)
rf_log10 <- postResample(pred = test_results$rf_log10,  obs = test_results$dea_robust)
```

0.6638687
0.01834957
  RMSE  Rsquared       MAE 
0.8862600 0.6474117 0.8848043 

data chosen II - ideology score
0.6631807
MAE
0.01817255
RMSE   Rsquared        MAE 
0.04228648 0.65581593 0.03220443 

## Target cube root - Random forest

### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train((dea_robust)^(1/3) ~ .,
                     data = df_model_robust,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```
#### Data chosen I
Did not do first two correctly

  [1] "party_munPSOE"                "party_ccaaERC"                "party_ccaaPNV"                "party_ccaaPSOE"               "social_services"             
 [6] "tax_fin_admin"                "public_debt"                  "health"                       "infrastructure"               "employment_promotion"        
[11] "area_sqkm"                    "ue_pct_2020"                  "share_ue_construction"        "share_ue_industry"            "share_ue_agriculture"        
[16] "pop_share_foreigners"         "pop_share_wk_age"             "pop_share_retirees"           "share_essential_employment"   "share_contracts_agri"        
[21] "share_contracts_con"          "rural_prop_tax"               "revenue_tax_share"            "revenue_grants_share"         "share_ccaa_general_services" 
[26] "share_ccaa_security"          "share_ccaa_economic"          "share_ccaa_culture"           "share_ccaa_social_protection" "pop_density"                 
[31] "per_capita_contracts" 

data chosen II - ideology score

[1] "social_services"             "tax_fin_admin"               "public_debt"                 "health"                      "infrastructure"             
 [6] "employment_promotion"        "area_sqkm"                   "ue_pct_2020"                 "share_ue_construction"       "share_ue_industry"          
[11] "share_ue_agriculture"        "pop_share_foreigners"        "pop_share_wk_age"            "pop_share_retirees"          "share_women"                
[16] "share_essential_employment"  "share_firms_service"         "share_contracts_agri"        "share_contracts_con"         "rural_prop_tax"             
[21] "special_prop_tax"            "revenue_tax_share"           "revenue_grants_share"        "share_ccaa_general_services" "share_ccaa_security"        
[26] "share_ccaa_economic"         "share_ccaa_culture"          "pop_density"                 "per_capita_contracts" 

```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "party")&!startsWith(non_zero_vars, "greater")]


df_model_final <- 
  df_model_imp |>
  dplyr::select(all_of(non_zero_vars), dea_robust, INE, NOMBRE)|> 
  drop_na()
# excluded party ccaa for the moment
```

Hypothesis: covid employment data makes models overfit --\> too accurate AND decreases R-squared. How?


#### Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_model_final$dea_robust |> 
  createDataPartition(p = 0.75, list = FALSE)

train.data  <- df_model_final[training.samples, ]
test.data <- df_model_final[-training.samples, ] 

# deleting INE and NOMBRE from train set to keep in test only
train.data$INE <- NULL
train.data$NOMBRE <- NULL

```

#### Training RF
```{r}
ctrl <- trainControl(method = "cv", number = 5)

set.seed(3456)
rf_tune_cube <- train((dea_robust)^(1/3) ~., 
                 data = train.data,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(9,12,15,18,21)),
                 importance = TRUE)

rf_tune_cube$finalModel$importance

rf_tune_cube$results

varImp(rf_tune_cube)

plot(varImp(rf_tune_cube))
```

##### Results
```{r}
# cube
test_results$rf_cube <- predict(rf_tune_cube, test.data)
test_results$rf_cube <- (test_results$rf_cube)^3
rf_cube <- postResample(pred = test_results$rf_cube,  obs = test_results$dea_robust)
```


0.6542624
MAE
0.01300218
     RMSE  Rsquared       MAE 
0.1562569 0.6477807 0.1460189 

data chosen II
0.6619849
MAE
0.01284411
RMSE   Rsquared        MAE 
0.04242569 0.65422809 0.03235297 


#### Compare Results

```{r}
cube_df <- as.data.frame(t(rf_cube))
log_df <- as.data.frame(t(rf_log))
normal_df <- as.data.frame(t(rf_normal))
log10_df <- as.data.frame(t(rf_log10))

cube_df$model <- "Cube Root"
log_df$model <- "Log"
normal_df$model <- "Normal"
log10_df$model <- "Log10"

rf_metrics_table <- rbind(cube_df, log_df, normal_df, log10_df)

rf_metrics_table
```


#### Visualizing best

```{r}
qplot(test_results$rf, test_results$dea_robust) + 
  labs(title="RF Regression Observed VS Predicted", x="Predicted", y="Observed") +
  geom_abline(intercept = 0, slope = 1, colour = "blue") +
  theme_bw()
```

Problem --> Absolute error

## MAE Investigation

```{r}
# normal
mae_per_observation_rf <- abs(test_results$rf - test_results$dea_robust)
test.data$mae_rf <- mae_per_observation_rf 
```

```{r}
df_mae <- 
  test.data |> 
  select(INE, NOMBRE, mae_rf) |> 
  left_join(df_dea, by = c("INE", "NOMBRE")) |> 
  drop_na()
```

## DELETE
#### PDP

```{r}
partial(rf_tune$finalModel, pred.var = "ue_pct_2020", plot = TRUE, rug = T, train = train.data)
autoplot(pdp_rf) +
  labs(title = "Partial Dependence Plot", x = "Feature Name", y = "Predicted Outcome") +
  theme_minimal()

?partial
```

### SHAP

Importance Bee Plot

```{r}
X <- train.data[sample(nrow(train.data), 1000), -which(names(train.data) == "dea_robust")]
bg_X <- train.data[sample(nrow(train.data), 100), -which(names(train.data) == "dea_robust")]

s <- kernelshap(rf_tune, X = X, bg_X = bg_X) 
sv <- shapviz(s)
sv_importance(sv, kind = "bee", max_display = Inf)
```

Dependence

```{r}
v_select_1 <- c("per_capita_contracts", "pop_density", "pop_share_wk_age", "area_sqkm", "rural_prop_tax", "social_services", "employment_promotion", "party_mun")
sv_dependence(sv, v = v_select_1)
```
## DELETE

### Correlation Analysis

```{r}
df_corr_mae <-
  df_mae |> 
  select_if(is.numeric) |> 
  select(-mae_rf_log, -mae_rf_log10, -mae_rf_cube, -mae_rf)

corr_mae<- cor(df_mae$mae_rf, df_corr_mae, method = "spearman")
corr_mae<-round(corr_mae,4)

df_corr_mae_results <- 
  data.frame(corr_mae) |> 
  pivot_longer(values_to = "correlation",
               cols = 1:69,
               names_to = "variable")

ggplot(df_corr_mae_results, aes(x = variable, y = correlation)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Correlation with absolute error", x = "Variable", y = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) 
```

#### dea_robust variable

```{r}
df_mae |> 
  ggplot()+
  geom_point(aes(x = dea_robust, y = mae_rf)) +
  theme_minimal()
```

#### Mapping MAE

```{r}
esp_can <- esp_get_country() 
can_prov <- esp_get_can_provinces()
can_box <- esp_get_can_box() 
munic <- esp_get_munic() 

munic <-    
  munic |>  
  rename(INE = LAU_CODE)

df_mae_map <- munic |> 
  left_join(df_mae, by = "INE")  

ggplot(esp_can) +
  geom_sf() +
  geom_sf(data = can_prov) +
  geom_sf(data = can_box) + 
  geom_sf(data = df_mae_map, aes(fill = mae_rf), color = "black", size = .5)+
  scale_fill_viridis_c(na.value = NA) +
  theme_minimal()
```

No spatial relationship

```{r}
df_mae |> 
  ggplot()+
  geom_point(aes(x = area_sqkm, y = mae_rf)) +
  theme_minimal()+
    coord_cartesian(xlim = c(0, 300), ylim = c(0, 0.18))
```

### Linear regression

```{r}
df_mae_lm <-
  na.omit(df_mae) |> 
  select(-c(INE, NOMBRE, CCAA, party_ccaa, party_mun, median_inc_con_unit, target, dea_robust))
model <- lm(mae_rf ~ ., data = df_mae_lm)

# Print summary of the model
summary(model)
```
### Absoulte error by Regions (Province and Autonomous Community)

```{r}
CPRO_mae <- df_mae |> 
  group_by(CPRO) |> 
  summarise(mae_rf = mean(mae_rf, na.rm = TRUE))

# Create the graph
ggplot(CPRO_mae, aes(x = CPRO, y = mae_rf)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Mean Absolute Error by Province",
       x = "Regional Area (CPRO)",
       y = "Mean Absolute Error") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
CCAA_mae <- df_mae |> 
  group_by(CCAA) |> 
  summarise(mae_rf = mean(mae_rf, na.rm = TRUE))

# Create the graph
ggplot(CCAA_mae, aes(x = CCAA, y = mae_rf)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  labs(title = "Mean Absolute Error by CCAA",
       x = "Autonomous Community",
       y = "Mean Absolute Error") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
ggplot(df_mae) +
    geom_point(aes(x = pop_density, y = mae_rf)) +
    theme_minimal() +
    coord_cartesian(xlim = c(0, 300), ylim = c(0, 0.18))
```

```{r}
ggplot(df_mae) +
    geom_point(aes(x = ue_pct_2020, y = mae_rf)) +
    theme_minimal() +
    coord_cartesian(xlim = c(0, 60), ylim = c(0, 0.18))
```

```{r}
df_mae |> 
  arrange(desc(MAE))
```

## Building the Model

## Feature Engineering

Selecting imputed data frame while keeping CCAA and CPRO

```{r}
df_ml <- 
  df_model_imp |> 
  select(-c(INE, NOMBRE, CCAA)) 
```


Adding features

bivariat:

pop_density --\> threshold: 50

area_sqkm --\> trheshold: 50

pop_total --\> threshold: 500

keep CPRO

Interactions:

All of the above

Function
```{r}
generate_interactions <- function(df) {
  # Extracting numeric columns excluding dea_robust
  numeric_cols <- df %>%
    select(where(is.numeric), -dea_robust)
  
  # Extracting pop_total column
  pop_total_col <- numeric_cols %>%
    select(pop_total, pop_density, area_sqkm)
  
  # Other numeric columns excluding pop_total
  other_numeric_cols <- numeric_cols %>%
    select(-c(pop_total, pop_density, area_sqkm))
  
  # Generating interactions
  interaction_cols <- list()
  
  for(col_name in names(other_numeric_cols)) {
    interaction_name <- paste("pop_total", col_name, sep = "_x_")
    interaction_name <- make.names(interaction_name, unique = TRUE)  # Ensure unique column names
    interaction_cols[[interaction_name]] <- pop_total_col[[1]] * other_numeric_cols[[col_name]]
  }
  
  # Combining original and interaction columns
  df_interactions <- cbind(df, as.data.frame(interaction_cols))
  
  return(df_interactions)
}
```


```{r}
# to apply feature engineering
vars_to_engineer <- 
  df_ml |> 
  select(where(is.numeric)) |> 
  names()

# feature engineering
df_ml <- 
  df_ml |> 
  mutate(pop_density_low = as.factor(if_else(pop_density < 50, 1,0)), # adding varaibles
         pop_total_low = as.factor(if_else(pop_total < 500, 1,0)),
         area_sqkm_low = as.factor(if_else(area_sqkm < 50, 1,0))) |>
  generate_interactions() |> 
  mutate(across(all_of(vars_to_engineer), ~log(. + 1), .names = "{.col}_log"), # feature engineering mathematical alteration of variables
         across(all_of(vars_to_engineer), ~.^2, .names = "{.col}_2"),
         across(all_of(vars_to_engineer), ~.^3, .names = "{.col}_3")) |> 
  drop_na()

df_ml$dea_robust_2 <- NULL
df_ml$dea_robust_log <- NULL
df_ml$dea_robust_3 <- NULL
df_ml$CPRO <- as.factor(df_ml$CPRO)
```

## Feature selection

### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train(dea_robust ~ .,
                     data = df_ml,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```

#### Data chosen
No interactions
[1] "CPRO04"                          "CPRO05"                          "CPRO06"                          "CPRO09"                         
 [5] "CPRO10"                          "CPRO11"                          "CPRO12"                          "CPRO13"                         
 [9] "CPRO14"                          "CPRO16"                          "CPRO18"                          "CPRO19"                         
[13] "CPRO20"                          "CPRO21"                          "CPRO22"                          "CPRO23"                         
[17] "CPRO24"                          "CPRO28"                          "CPRO29"                          "CPRO31"                         
[21] "CPRO33"                          "CPRO34"                          "CPRO35"                          "CPRO37"                         
[25] "CPRO38"                          "CPRO39"                          "CPRO40"                          "CPRO41"                         
[29] "CPRO42"                          "CPRO43"                          "CPRO45"                          "CPRO46"                         
[33] "CPRO47"                          "CPRO48"                          "CPRO50"                          "social_services"                
[37] "tax_fin_admin"                   "health"                          "employment_promotion"            "share_ue_service"               
[41] "share_ue_construction"           "share_ue_industry"               "share_ue_agriculture"            "pop_share_foreigners"           
[45] "pop_share_wk_age"                "greater_20k1"                    "share_contracts_agri"            "share_contracts_con"            
[49] "share_contracts_serv"            "urban_prop_tax"                  "share_ccaa_general_services"     "pop_density_low1"               
[53] "pop_total_low1"                  "area_sqkm_low1"                  "environment_log"                 "social_services_log"            
[57] "public_debt_log"                 "employment_promotion_log"        "sports_log"                      "gov_bodies_log"                 
[61] "pub_transportation_log"          "pensions_log"                    "area_sqkm_log"                   "ue_pct_2020_log"                
[65] "share_ue_construction_log"       "share_ue_industry_log"           "share_ue_agriculture_log"        "share_ue_wo_job_log"            
[69] "pop_share_wk_age_log"            "share_firms_service_log"         "revenue_other_share_log"         "share_ccaa_general_services_log"
[73] "share_ccaa_economic_log"         "pop_density_log"                 "per_capita_contracts_log"        "infrastructure_2"               
[77] "share_essential_employment_2"    "urban_prop_tax_2"                "per_capita_contracts_2"          "general_services_3"             
[81] "environment_3"                   "housing_urban_plan_3"            "area_sqkm_3"                     "pop_share_foreigners_3"         
[85] "pop_share_youth_3"               "share_essential_business_3"      "share_essential_employment_3"    "share_firms_service_3"          
[89] "rural_prop_tax_3"                "revenue_grants_share_3"          "share_ccaa_security_3"           "share_ccaa_housing_services_3"        
[97] "share_ccaa_housing_services_3" 

Selected interactions
[1] "CPRO04"                           "CPRO05"                           "CPRO06"                           "CPRO09"                          
 [5] "CPRO10"                           "CPRO11"                           "CPRO12"                           "CPRO13"                          
 [9] "CPRO14"                           "CPRO16"                           "CPRO18"                           "CPRO19"                          
[13] "CPRO20"                           "CPRO21"                           "CPRO22"                           "CPRO23"                          
[17] "CPRO24"                           "CPRO28"                           "CPRO29"                           "CPRO31"                          
[21] "CPRO33"                           "CPRO34"                           "CPRO35"                           "CPRO37"                          
[25] "CPRO38"                           "CPRO39"                           "CPRO40"                           "CPRO41"                          
[29] "CPRO42"                           "CPRO43"                           "CPRO45"                           "CPRO46"                          
[33] "CPRO47"                           "CPRO48"                           "CPRO50"                           "social_services"                 
[37] "tax_fin_admin"                    "health"                           "employment_promotion"             "share_ue_service"                
[41] "share_ue_construction"            "share_ue_industry"                "share_ue_agriculture"             "pop_share_foreigners"            
[45] "pop_share_wk_age"                 "greater_20k1"                     "share_contracts_agri"             "share_contracts_con"             
[49] "share_contracts_serv"             "urban_prop_tax"                   "share_ccaa_general_services"      "pop_density_low1"                
[53] "pop_total_low1"                   "area_sqkm_low1"                   "pop_total_x_pop_share_foreigners" "environment_log"                 
[57] "social_services_log"              "public_debt_log"                  "employment_promotion_log"         "sports_log"                      
[61] "gov_bodies_log"                   "pub_transportation_log"           "pensions_log"                     "area_sqkm_log"                   
[65] "ue_pct_2020_log"                  "share_ue_construction_log"        "share_ue_industry_log"            "share_ue_agriculture_log"        
[69] "share_ue_wo_job_log"              "pop_share_wk_age_log"             "share_firms_service_log"          "revenue_other_share_log"         
[73] "share_ccaa_general_services_log"  "share_ccaa_economic_log"          "pop_density_log"                  "per_capita_contracts_log"        
[77] "infrastructure_2"                 "share_essential_employment_2"     "urban_prop_tax_2"                 "per_capita_contracts_2"          
[81] "general_services_3"               "environment_3"                    "housing_urban_plan_3"             "area_sqkm_3"                     
[85] "pop_share_foreigners_3"           "pop_share_youth_3"                "share_essential_business_3"       "share_essential_employment_3"    
[89] "share_firms_service_3"            "rural_prop_tax_3"                 "revenue_grants_share_3"           "share_ccaa_security_3"           
[93] "share_ccaa_housing_services_3"   

```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "CPRO")&!startsWith(non_zero_vars, "greater")&!endsWith(non_zero_vars, "low1")]

df_ml_final <- 
  df_ml |>
  dplyr::select(all_of(non_zero_vars), dea_robust, CPRO, area_sqkm_low, pop_density_low, pop_density_low, greater_20k)
```

Hypothesis: covid employment data makes models overfit --\> too accurate AND decreases R-squared. How?


#### Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_ml_final$dea_robust |> 
  createDataPartition(p = 0.75, list = FALSE)

train.data  <- df_ml_final[training.samples, ]
test.data <- df_ml_final[-training.samples, ] 
```

### Training Random forest

```{r}
ctrl <- trainControl(method = "cv", number = 5)

set.seed(3456)
rf_tune_final <- train(dea_robust ~., 
                 data = train.data,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(12, 15, 18,21)),
                 importance = TRUE)

rf_tune_final$finalModel$importance

rf_tune_final$results

varImp(rf_tune_final)

plot(varImp(rf_tune_final))
```

#### Results
No interactions
0.6768359
MAE
0.03193727
RMSE   Rsquared        MAE 
0.04178746 0.66914071 0.03208257 

Interactions municipality size variables + log, ^2, ^3
0.6771943	
MAE
0.03183867
RMSE   Rsquared        MAE 
0.04191683 0.66573567 0.03215322 

```{r}
model_results <- data.frame(dea_robust = test.data$dea_robust)

model_results$rf <- predict(rf_tune_final, test.data)
postResample(pred = model_results$rf,  obs = model_results$dea_robust)
```
### XG Boost

```{r}
ctrl <- trainControl(method = "cv", number = 5)

set.seed(123)
xgb_tune <- train(dea_robust ~., 
                  data = train.data,
                  method = "xgbTree",
                  preProc=c('scale','center'),
                  objective = "reg:squarederror",
                  trControl = ctrl,
                  tuneGrid = expand.grid(nrounds = c(700, 800, 900, 1000, 1500), 
                                         max_depth = c(3,4,5,6,7, 8), 
                                         eta = c(0.1, 0.2, 0.3),
                                         gamma = c(0.05, 0.001, 0.025),
                                         colsample_bytree = c(0.4, 0.5),
                                         min_child_weight = c(1),
                                         subsample = c(0.5, 0.6,0.7,0.8)))

xgb_tune$results

varImp(xgb_tune)

plot(varImp(xgb_tune))

plot(xgb_tune)
```

```{r}
model_results$xg_boost <- predict(xgb_tune, test.data)
postResample(pred = model_results$xg_boost,  obs = model_results$dea_robust)
```


### Catboost

```{r}
catboost_model <- train(
  target ~ ., data = train_data,
  method = "catboost",
  trControl = train_control,
  tuneGrid = catboost_grid,
  preProc = c("center", "scale")
)
```


## Interpretation

### PDP

```{r}
partial(rf_tune$finalModel, pred.var = "ue_pct_2020", plot = TRUE, rug = T, train = train.data)
autoplot(pdp_rf) +
  labs(title = "Partial Dependence Plot", x = "Feature Name", y = "Predicted Outcome") +
  theme_minimal()

?partial
```

### SHAP

Importance Bee Plot

```{r}
X <- train.data[sample(nrow(train.data), 1000), -which(names(train.data) == "dea_robust")]
bg_X <- train.data[sample(nrow(train.data), 100), -which(names(train.data) == "dea_robust")]

s <- kernelshap(rf_tune, X = X, bg_X = bg_X) 
sv <- shapviz(s)
sv_importance(sv, kind = "bee", max_display = Inf)
```

Dependence

```{r}
v_select_1 <- c("per_capita_contracts", "pop_density", "pop_share_wk_age", "area_sqkm", "rural_prop_tax", "social_services", "employment_promotion", "party_mun")
sv_dependence(sv, v = v_select_1)
```

### Under and overachievers

```{r}

yhat = test_results$rf
hist(yhat, col="lightblue")

y = test_results$dea_robust
error = y-yhat
hist(error, col="lightblue")

noise <- error[1:100]

lwr <- yhat[101:length(yhat)] + quantile(noise,0.05, na.rm=T)
upr <- yhat[101:length(yhat)] + quantile(noise,0.95, na.rm=T)

predictions = data.frame(real=y[101:length(y)], fit=yhat[101:length(yhat)], lwr=lwr, upr=upr)

predictions = predictions %>% mutate(out=factor(if_else(real<lwr | real>upr,1,0)))

mean(predictions$out==1)

ggplot(predictions, aes(x=fit, y=real))+
  geom_point(aes(color=out)) + theme(legend.position="none") +
  geom_ribbon(data=predictions,aes(ymin=lwr,ymax=upr),alpha=0.3) +
  labs(title = "Prediction intervals", x = "Prediction",y="Estimated Efficiency")
```