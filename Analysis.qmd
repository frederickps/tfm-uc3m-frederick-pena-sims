---
title: "Analysis"
format: html
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## Analysis

### Library

```{r}
options(scipen = 999)
library(tidyverse)
library(readxl)
library(rDEA)
library(caret)
library(mice)
library(xgboost)
```

### Load data (if needed)

```{r}
df_final <- read.csv("Data/TFM_data_2024-05-20.csv", colClasses = c(INE = "character")) |> 
  select(-X)
```


### Data Envelopment Analysis

Ideas:

Unemployment as outcome Contracts as outcome (contracts per capita)

-   variables for DEA:

-   n_firms

-   per capita CCAA spending

-   per capita mun spending

-   distance

-   unemployment rate

-   variables for prediction task

    -   how money was spent
    -   population (absolute number)
    -   pop share foreigners
    -   pop share working age
    -   average age
    -   median income per household unit (?)
    -   contracts mean 2023
    -   greater 20k
    -   pop density

More idea - contracts divided by area (contracts database)

------------------------------------------------------------------------

In the context of Data Envelopment Analysis (DEA) and efficiency estimation, censoring refers to the phenomenon where efficiency scores are bounded or capped at a certain value. This means that despite variations in input-output combinations among decision-making units (DMUs), a substantial number of DMUs are assigned the maximum efficiency score (often 1) by the DEA model.

When efficiency scores are "censored," it implies that the DEA model is unable to distinguish between highly efficient DMUs, resulting in a clustering of efficiency scores at the upper bound (e.g., 1). This can occur due to various factors such as data limitations, measurement errors, model assumptions, or the inherent characteristics of the production process being analyzed.

------------------------------------------------------------------------

Taking the inverse of unemployment because output oriented DEA defines higher values as better

Using per capita spending on CCAA level and distance from provincial capital as environmental variables

Variable Returns to Scale (RTS = "Variable"): This assumption allows for flexibility in the relationship between inputs and outputs. It recognizes that the impact of municipal spending on reducing unemployment may vary across municipalities due to factors such as local economic conditions, labor market dynamics, and policy effectiveness.

## DEA
### Naive
```{r}
X <- df_final[c("n_firms", "per_capita_MUN", "per_capita_CCAA", "dist_prov_cap")]

Y <- df_final[c("target")]
Y <- 
  Y |> 
  mutate(target = (target * -1)+100) # DEA does not know how to handel negative value --> adding 100 to 

# Mean normalization function
mean_normalize <- function(x) {
  return((x - mean(x)) / (max(x) - min(x))+1)
}

# Apply mean normalization to each column
X <- X %>% mutate(across(everything(), mean_normalize))

Y <- Y |> mutate(across(everything(), mean_normalize))

dea_naive <- 
  dea(XREF=X, YREF=Y, X=X, Y=Y,model="output", RTS="variable")
```

Data frame

```{r}
df_dea <- 
  df_final |> 
  mutate(dea_naive = dea_naive$thetaOpt) 
```
,
         ue_pct_2023 = 100 - ue_pct_2023
         
target = (target * -1)+100

### Robust
```{r}
X <- df_final[c("n_firms", "per_capita_MUN")]

Y <- df_final[c("target", "ue_pct_2023")]
Y <- 
  Y |> 
  mutate(target = (target * -1)+100,
         ue_pct_2023 = 100 - ue_pct_2023) # DEA does not know how to handle negative value --> adding 100 to 

Z <- df_final[c("dist_prov_cap", "per_capita_CCAA")]

# Mean normalization function
mean_normalize <- function(x) {
  return((x - mean(x)) / (max(x) - min(x))+1)
}

# Apply mean normalization to each column
X <- X %>% mutate(across(everything(), mean_normalize))

Z <- Z %>% mutate(across(everything(), mean_normalize))

Y <- Y |> mutate(across(everything(), mean_normalize))

dea_robust <- 
  dea.env.robust(X, Y, W=NULL, Z, model="output", RTS="variable",
                L1=10, L2=100, alpha=0.05)
```
Calculating the efficiency score

```{r}
sorted_scores <- sort(dea_robust$delta_hat_hat, decreasing = TRUE)
best_score <- max(sorted_scores)
delta_hat_hat <- dea_robust$delta_hat_hat

df_dea <- 
  df_dea |> 
  mutate(dea_robust = delta_hat_hat/best_score) 
```

## Finalizing data frame

### Variable selection

All variables without additional meaning and variables used in estimating efficiency score

```{r}
df_model <- 
  df_dea |> 
  select(-c(INE, NOMBRE, CCAA, CODAUTO, CPRO, total_CCAA, total_MUN, pop_below_16, pop_16_64, pop_above_65, pop_foreigners, target, dist_prov_cap, per_capita_CCAA, per_capita_MUN, n_firms, ue_pct_2023, contracts_mean_2022))
```

### Data imputation

```{r}
m <- 5
set.seed(475)
imp <- mice(df_model, m = m, method= "rf")
df_model_imp <- complete(imp, action=m)

df_model_imp <- 
  df_model_imp |> 
  filter(!is.na(party_mun))
```

## Analysis - Naive

### Descriptive analysis of results 

#### Distribution 

```{r}
df_dea |> 
  ggplot()+
  geom_histogram(aes(dea_naive))
```

#### Most efficient municipalities

```{r}
df_dea |> 
  filter(dea_naive == 1) |> 
  count()
```

```{r}
df_efficient <- 
  df_dea |> 
  filter(dea_naive == 1)
  
df_efficient |> 
  count(CCAA)

df_efficient |> 
  count(greater_20k)
```

#### Mean efficiency score

```{r}
mean(df_dea$dea_naive)
```
8476198

#### t-test between city sizes

```{r}
greater_20k <- df_dea[df_dea$greater_20k == 1, "dea_naive"]
smaller_20k <- df_dea[df_dea$greater_20k == 0, "dea_naive"]

# Perform the t-test
t_test_result <- t.test(greater_20k, smaller_20k)
t_test_result
```
The mean DEA efficiency score for observations where "greater_20k" is 1 is 0.8735019, while the mean DEA efficiency score for observations where "greater_20k" is 0 is 0.8460489.


```{r}
greater_100k <- df_dea[df_dea$pop_total > 100000, "dea_naive"]
smaller_100k <- df_dea[df_dea$pop_total <= 100000, "dea_naive"]

# Perform the t-test
t_test_result <- t.test(greater_100k, smaller_100k)
t_test_result
```
## Building the model



### Correlation - naive

```{r}
df_model_naive <- 
  df_model_imp |> 
  select(-dea_robust)
```


```{r}
df_corr <-
  df_model_naive |> 
  dplyr::select(-dea_naive) |>
  select_if(is.numeric)

corr<- cor(df_model_naive$dea_naive, df_corr)
corr<-round(corr,4)

df_corr_results <- 
  data.frame(corr) |> 
  pivot_longer(values_to = "correlation",
               cols = 1:32,
               names_to = "variable")

ggplot(df_corr_results, aes(x = variable, y = correlation)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Correlation with DEA efficiency score", x = "Variable", y = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) 
```




### Feature engineering

```{r}
ggplot(df_model_imp)+
  geom_point(aes(x = median_inc_con_unit, y = dea_naive))
```

### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train(dea_naive ~ .,
                     data = df_model_naive,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```

```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "party")]


df_model_final <- 
  df_model_imp |> 
  dplyr::select(all_of(non_zero_vars), party_mun, party_ccaa, dea_naive )
```

### Modelling

#### Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_model_final$dea_naive |> 
  createDataPartition(p = 0.8, list = FALSE)

train.data  <- df_model_final[training.samples, ]
test.data <- df_model_final[-training.samples, ] 
```

#### Random forest 

```{r}
set.seed(3456)
rf_tune <- train(dea_naive ~.,  
                 data = train.data,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(17,18,19,20,21,22)),
                 importance = TRUE)

rf_tune$finalModel$importance

rf_tune$results

plot(varImp(rf_tune))
```
#### Highest

only target 
0.4654844

only target (but per_capita_contracts in DEA)
0.4433757

only target (population > 2500)
0.2527986

target + ue_pct_2023 + per_capita_contracts
0.3568178

target + per capita_contracts (including ue_pct_2022 as predictor)
0.4476367

target + per capita_contracts (population > 2500)
0.2638064

```{r}
plot(rf_tune)
```

#### Gradiant boosting

```{r}
set.seed(123)
xgb_tune <- train(dea_naive ~., 
                  data = train.data,
                  method = "xgbTree",
                  preProc=c('scale','center'),
                  objective = "reg:squarederror",
                  trControl = ctrl,
                  tuneGrid = expand.grid(nrounds = c(700, 800, 900, 1000, 1500), 
                                         max_depth = c(7, 8), 
                                         eta = c(0.1),
                                         gamma = c(0.1, 0.3, 0.5, 0.7, 0.9, 1),
                                         colsample_bytree = c(0.2, 0.3, 0.4, 0.5),
                                         min_child_weight = c(1),
                                         subsample = c(0.8)))

xgb_tune

plot(xgb_tune)
```

## Analysis - Robust

### Distribution

```{r}
df_dea |> 
  ggplot()+
  geom_histogram(aes(dea_robust))

df_dea |> 
  filter(dea_robust == 1)
```


### Correlation - robust

```{r}
df_model_robust <- 
  df_model_imp |> 
  select(-dea_naive)
```


```{r}
df_corr <-
  df_model_robust |> 
  dplyr::select(-dea_robust) |>
  select_if(is.numeric)

corr<- cor(df_model_robust$dea_robust, df_corr)
corr<-round(corr,4)

df_corr_results <- 
  data.frame(corr) |> 
  pivot_longer(values_to = "correlation",
               cols = 1:32,
               names_to = "variable")

ggplot(df_corr_results, aes(x = variable, y = correlation)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "Correlation with DEA efficiency score", x = "Variable", y = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0.5)) 
```

### Lasso regression

```{r}
# Define the control parameters for LASSO regression
ctrl <- trainControl(method = "cv", number = 5)  # 5-fold cross-validation

# Train the LASSO model
set.seed(123)
lasso_model <- train(dea_robust ~ .,
                     data = df_model_robust,
                     method = "glmnet",
                     trControl = ctrl,
                     tuneGrid = expand.grid(alpha = 1, lambda = seq(0.001, 1, length = 100)))

lasso_coef <- coef(lasso_model$finalModel, s = lasso_model$finalModel$lambdaOpt)

non_zero_vars <- rownames(lasso_coef)[lasso_coef[,1]!=0]

non_zero_vars <- non_zero_vars[-1] 

non_zero_vars
```

```{r}
non_zero_vars <- non_zero_vars[!startsWith(non_zero_vars, "party")]


df_model_final <- 
  df_model_robust |> 
  dplyr::select(all_of(non_zero_vars), dea_robust, party_mun, party_ccaa, greater_20k)
```

### Modelling

#### Training and testing

```{r}
set.seed(123)  
training.samples <-
  df_model_final$dea_robust |> 
  createDataPartition(p = 0.8, list = FALSE)

train.data  <- df_model_final[training.samples, ]
test.data <- df_model_final[-training.samples, ] 
```

#### Random forest 

```{r}
set.seed(3456)
rf_tune <- train(dea_robust ~., 
                 data = train.data,
                 method = "rf",
                 preProc=c('scale','center'),
                 trControl = ctrl,
                 ntree = 100,
                 tuneGrid = data.frame(mtry=c(9,12,15,18,21)),
                 importance = TRUE)

rf_tune$finalModel$importance

rf_tune$results

varImp(rf_tune)
```
##### Highest

only target (population > 2500)
0.2427973	

target + ue_pct_2023
Rsquared 0.3027631

target + ue_pct_2023 (population > 1000)
Rsquared 0.2685074

target + ue_pct_2023 (population > 2500)
Rsquared: 0.3909410	

target + ue_pct_2023 + per_capita_contracts
Rsquared 0.2701871

target + per_capita_contracts (including ue_pct_2022)
0.1292275

target + per_capita_contracts (population > 1000)
0.1627656

target + per_capita_contracts (population > 5000)
0.2952929



```{r}
set.seed(123)
xgb_tune <- train(dea_robust ~., 
                  data = train.data,
                  method = "xgbTree",
                  preProc=c('scale','center'),
                  objective = "reg:squarederror",
                  trControl = ctrl,
                  tuneGrid = expand.grid(nrounds = c(700, 800, 900, 1000, 1500), 
                                         max_depth = c(7, 8), 
                                         eta = c(0.1),
                                         gamma = c(0.05, 0.1, 0.15),
                                         colsample_bytree = c(0.4, 0.5),
                                         min_child_weight = c(1),
                                         subsample = c(0.8)))

xgb_tune

plot(xgb_tune)
```

